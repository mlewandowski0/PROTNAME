{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KMTa-R8A6jiI",
    "outputId": "268501f2-cc48-4b81-d027-87d5ae402d45",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"\\x1b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\\x1b[0m\\x1b[33m\",\n",
       " '\\x1b[0m',\n",
       " '\\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m A new release of pip is available: \\x1b[0m\\x1b[31;49m23.0.1\\x1b[0m\\x1b[39;49m -> \\x1b[0m\\x1b[32;49m23.1.2\\x1b[0m',\n",
       " '\\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m To update, run: \\x1b[0m\\x1b[32;49mpython -m pip install --upgrade pip\\x1b[0m']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q transformers datasets matplotlib\n",
    "!!pip install -q accelerate torchinfo huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected operating system as Ubuntu/focal.\n",
      "Checking for curl...\n",
      "Detected curl...\n",
      "Checking for gpg...\n",
      "Detected gpg...\n",
      "Detected apt version as 2.0.9\n",
      "Running apt-get update... done.\n",
      "Installing apt-transport-https... done.\n",
      "Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n",
      "Importing packagecloud gpg key... Packagecloud gpg key imported to /etc/apt/keyrings/github_git-lfs-archive-keyring.gpg\n",
      "done.\n",
      "Running apt-get update... done.\n",
      "\n",
      "The repository is setup! You can now install packages.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "git-lfs is already the newest version (3.3.0).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\n",
    "!apt-get install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e23a126f1240e48a3b2aa4e35cf6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Qpd_5bdc6sxf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import T5ForConditionalGeneration, T5Config, AdamW\n",
    "from tqdm.auto import tqdm\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "J_tfT6Ll6wKh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_id = '1yXvDTRRxjCLyAf4icU1sEMKF0NpssCnC'\n",
    "destination = 'human_proteins.tsv'\n",
    "hf_name = \"t5-small\"\n",
    "max_length = 512\n",
    "tokenizer_folder = \"PROTNAME_tok\"\n",
    "save_folder = \"PROTNAME\"\n",
    "vocab_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1Mkm87uO7quF",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b214af991c4a81a38cafa27c811bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "saved all the data to human_proteins.tsv. total size : 12.9 MB\n"
     ]
    }
   ],
   "source": [
    "file_id = '1yXvDTRRxjCLyAf4icU1sEMKF0NpssCnC'\n",
    "destination = 'human_proteins.tsv'\n",
    "\n",
    "def format_size(value):\n",
    "  if value >= 1024**3:\n",
    "    return f\"{round(value / 1024**3 , 3)} GB\"\n",
    "  elif value >= 1024**2:\n",
    "    return f\"{round(value / 1024**2 , 3)} MB\"\n",
    "  elif value >= 1024:\n",
    "    return f\"{round(value / 1024 , 3)} KB\"\n",
    "  return f\"{value} B\"\n",
    "\n",
    "# Code taken from https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "    params = { 'id' : id, 'confirm' : 1 }\n",
    "    response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "    \n",
    "    pb = tqdm(response.iter_content(CHUNK_SIZE))\n",
    "    b_total = 0\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for i,chunk in enumerate(pb):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "                b_total += len(chunk)\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                  pb.set_description(f\"written : {format_size(b_total)}\")\n",
    "                i += 1\n",
    "    print(\"\\n\")\n",
    "    print(f\"saved all the data to {destination}. total size : {format_size(os.stat(destination).st_size)}\")\n",
    "\n",
    "\n",
    "download_file_from_google_drive(file_id, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ea35bbc507c41d7aa7ba02c0a790888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "saved all the data to all_proteins.tsv. total size : 294.963 MB\n"
     ]
    }
   ],
   "source": [
    "download_file_from_google_drive(\"1FLrC9kK5-R_NwjmX_WTqT8YqchzS9zIN\", \"all_proteins.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "21QymT2_8C48",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Protein Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M R W Q E M G Y I F Y P R K L R</td>\n",
       "      <td>Mitochondrial-derived peptide MOTS-c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M P G W F K K A W Y G L A S L L S F S S F I L ...</td>\n",
       "      <td>Clarin-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M K R R Q K R K H L E N E E S Q E T A E K G G ...</td>\n",
       "      <td>Protein FAM170A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M D D A D P E E R N Y D N M L K M L S D L N K ...</td>\n",
       "      <td>Synaptonemal complex central element protein 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M A F S D L T S R T V H L Y D N W I K D A D P ...</td>\n",
       "      <td>Elongation of very long chain fatty acids prot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20417</th>\n",
       "      <td>M P L A S P I Q H H E V T R G V A P S M A L R ...</td>\n",
       "      <td>Putative uncharacterized protein PRO3102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20418</th>\n",
       "      <td>M V R P H L L K K K I L G R V W W L M P V V L ...</td>\n",
       "      <td>Putative uncharacterized protein PRO2829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20419</th>\n",
       "      <td>M A E T Y R R S R Q H E Q L P G Q R H M D L L ...</td>\n",
       "      <td>Putative uncharacterized protein DKFZp434L187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20420</th>\n",
       "      <td>M A H H S L N T F Y I W H N N V L H T H L V F ...</td>\n",
       "      <td>Putative uncharacterized protein encoded by LI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20421</th>\n",
       "      <td>M G R K E H E S P S Q P H M C G W E D S Q K P ...</td>\n",
       "      <td>Putative uncharacterized protein GUCA1ANB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12617 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sequence   \n",
       "0                        M R W Q E M G Y I F Y P R K L R  \\\n",
       "4      M P G W F K K A W Y G L A S L L S F S S F I L ...   \n",
       "6      M K R R Q K R K H L E N E E S Q E T A E K G G ...   \n",
       "7      M D D A D P E E R N Y D N M L K M L S D L N K ...   \n",
       "8      M A F S D L T S R T V H L Y D N W I K D A D P ...   \n",
       "...                                                  ...   \n",
       "20417  M P L A S P I Q H H E V T R G V A P S M A L R ...   \n",
       "20418  M V R P H L L K K K I L G R V W W L M P V V L ...   \n",
       "20419  M A E T Y R R S R Q H E Q L P G Q R H M D L L ...   \n",
       "20420  M A H H S L N T F Y I W H N N V L H T H L V F ...   \n",
       "20421  M G R K E H E S P S Q P H M C G W E D S Q K P ...   \n",
       "\n",
       "                                            Protein Name  \n",
       "0                  Mitochondrial-derived peptide MOTS-c   \n",
       "4                                               Clarin-2  \n",
       "6                                       Protein FAM170A   \n",
       "7        Synaptonemal complex central element protein 3   \n",
       "8      Elongation of very long chain fatty acids prot...  \n",
       "...                                                  ...  \n",
       "20417           Putative uncharacterized protein PRO3102  \n",
       "20418           Putative uncharacterized protein PRO2829  \n",
       "20419      Putative uncharacterized protein DKFZp434L187  \n",
       "20420  Putative uncharacterized protein encoded by LI...  \n",
       "20421         Putative uncharacterized protein GUCA1ANB   \n",
       "\n",
       "[12617 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"human_proteins.tsv\", sep=\"\\t\")\n",
    "dataframe = dataframe[dataframe[\"Sequence\"].str.len() <= 510]\n",
    "dataframe = pd.read_csv(\"human_proteins.tsv\", sep=\"\\t\")\n",
    "dataframe = dataframe[dataframe[\"Sequence\"].str.len() <= 510]\n",
    "dataframe[\"Protein Name\"] = [v.split(\"(\")[0] for v in dataframe[\"Protein Name\"]]\n",
    "dataframe[\"Sequence\"] = [\" \".join(v) for v in dataframe[\"Sequence\"]]\n",
    "\n",
    "with open(\"Sequences.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(dataframe[\"Sequence\"].values))\n",
    "    \n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sequence</th>\n",
       "      <th>protein_name</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MRWQEMGYIFYPRKLR</td>\n",
       "      <td>Mitochondrial-derived peptide MOTS-c</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MPGWFKKAWYGLASLLSFSSFILIIVALVVPHWLSGKILCQTGVDL...</td>\n",
       "      <td>Clarin-2</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MKRRQKRKHLENEESQETAEKGGGMSKSQEDALQPGSTRVAKGWSQ...</td>\n",
       "      <td>Protein FAM170A</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MDDADPEERNYDNMLKMLSDLNKDLEKLLEEMEKISVQATWMAYDM...</td>\n",
       "      <td>Synaptonemal complex central element protein 3</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MAFSDLTSRTVHLYDNWIKDADPRVEDWLLMSSPLPQTILLGFYVY...</td>\n",
       "      <td>Elongation of very long chain fatty acids prot...</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619007</th>\n",
       "      <td>529106</td>\n",
       "      <td>MNSNAPAAVIVLAAGAGTRMKSKLPKVLHEIGGRSLLMHAITAARG...</td>\n",
       "      <td>Bifunctional protein GlmU [Includes: UDP-N-ace...</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619008</th>\n",
       "      <td>529107</td>\n",
       "      <td>MSATGSDPSRRPVDLPDLSREAVPGEKVALAPGQLQLRPTRRGKAP...</td>\n",
       "      <td>Probable dual-specificity RNA methyltransferas...</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619009</th>\n",
       "      <td>529108</td>\n",
       "      <td>MVLASHNAKKLRELQRILAPAVPGLEAEQIVSAAGLGLPDVVEDAV...</td>\n",
       "      <td>dITP/XTP pyrophosphatase</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619010</th>\n",
       "      <td>529109</td>\n",
       "      <td>MLPVLTADALRTAEQAHWDEHPGDDLMGRAAAEVARHATEMLGDGP...</td>\n",
       "      <td>ADP-dependent</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619011</th>\n",
       "      <td>529110</td>\n",
       "      <td>MTAARALAGARVIVGVGGGIAAYKAAHVVRGLVASGAEVRVIPTAS...</td>\n",
       "      <td>Coenzyme A biosynthesis bifunctional protein C...</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619012 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                           sequence   \n",
       "0                0                                   MRWQEMGYIFYPRKLR  \\\n",
       "1                1  MPGWFKKAWYGLASLLSFSSFILIIVALVVPHWLSGKILCQTGVDL...   \n",
       "2                2  MKRRQKRKHLENEESQETAEKGGGMSKSQEDALQPGSTRVAKGWSQ...   \n",
       "3                3  MDDADPEERNYDNMLKMLSDLNKDLEKLLEEMEKISVQATWMAYDM...   \n",
       "4                4  MAFSDLTSRTVHLYDNWIKDADPRVEDWLLMSSPLPQTILLGFYVY...   \n",
       "...            ...                                                ...   \n",
       "619007      529106  MNSNAPAAVIVLAAGAGTRMKSKLPKVLHEIGGRSLLMHAITAARG...   \n",
       "619008      529107  MSATGSDPSRRPVDLPDLSREAVPGEKVALAPGQLQLRPTRRGKAP...   \n",
       "619009      529108  MVLASHNAKKLRELQRILAPAVPGLEAEQIVSAAGLGLPDVVEDAV...   \n",
       "619010      529109  MLPVLTADALRTAEQAHWDEHPGDDLMGRAAAEVARHATEMLGDGP...   \n",
       "619011      529110  MTAARALAGARVIVGVGGGIAAYKAAHVVRGLVASGAEVRVIPTAS...   \n",
       "\n",
       "                                             protein_name  length  \n",
       "0                   Mitochondrial-derived peptide MOTS-c       16  \n",
       "1                                                Clarin-2     232  \n",
       "2                                        Protein FAM170A      330  \n",
       "3         Synaptonemal complex central element protein 3       88  \n",
       "4       Elongation of very long chain fatty acids prot...     281  \n",
       "...                                                   ...     ...  \n",
       "619007  Bifunctional protein GlmU [Includes: UDP-N-ace...     492  \n",
       "619008  Probable dual-specificity RNA methyltransferas...     428  \n",
       "619009                          dITP/XTP pyrophosphatase      203  \n",
       "619010                                     ADP-dependent      492  \n",
       "619011  Coenzyme A biosynthesis bifunctional protein C...     425  \n",
       "\n",
       "[619012 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe2 = pd.read_csv(\"all_proteins.tsv\", sep=\"\\t\")\n",
    "dataframe2 = dataframe2[dataframe2[\"sequence\"].str.len() <= 510]\n",
    "dataframe2 = dataframe2[dataframe2[\"sequence\"].str.len() <= 510]\n",
    "dataframe2[\"protein_name\"] = [v.split(\"(\")[0] for v in dataframe2[\"protein_name\"]]\n",
    "\n",
    "with open(\"names.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([v.split(\"(\")[0].strip() for v in dataframe2[\"protein_name\"].values]))  \n",
    "\n",
    "dataframe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7824ce6896146a1920f859e72854925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/186 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a988cec1e4f44b08bd80211bc9921364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/1.51M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec63d16a7f0a4ce18ca22036c0e3d758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/3.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mlewand/PROT5-small\", max_length=512,\n",
    "                                                   padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 118, 89, 204, 116, 100, 118, 92, 131, 110, 115, 131, 88, 89, 104, 85, 89, 2] <s> M R W Q E M G Y I F Y P R K L R</s>\n",
      "[1, 249, 9701, 12, 25, 2] <s> Protein FAM170A</s>\n"
     ]
    }
   ],
   "source": [
    "ids = tokenizer.encode(\"M R W Q E M G Y I F Y P R K L R\")\n",
    "print(ids, tokenizer.decode(ids))\n",
    "ids = tokenizer.encode(\"Protein FAM170A\")\n",
    "print(ids, tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95364ca2d7164e83ad86febca12f1d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12617 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93b940c5783421ab1705b42a5ff2542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12617 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb2a71bc411448181d31957891a2281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_tokenized_X = []\n",
    "_tokenized_Y = []\n",
    "\n",
    "tokenized_X = []\n",
    "tokenized_Y = []\n",
    "sizes_X = []\n",
    "sizes_Y = []\n",
    "\n",
    "max_length_inp = 512\n",
    "max_length_out = 32 \n",
    "\n",
    "for x in tqdm(dataframe[\"Sequence\"]):\n",
    "    input_tokens = tokenizer.encode(x)\n",
    "    tokenized_X.append(input_tokens)\n",
    "    sizes_X.append(len(input_tokens))\n",
    "\n",
    "for y in tqdm(dataframe[\"Protein Name\"]):\n",
    "    out_tokens = tokenizer.encode(y)\n",
    "    tokenized_Y.append(out_tokens)\n",
    "    sizes_Y.append(len(out_tokens))\n",
    "    \n",
    "for x,y in tqdm(zip(_tokenized_X, _tokenized_Y)):\n",
    "   if len(x) <= max_length_inp and len(y) <= max_length_out:\n",
    "    tokenized_X.append(x)\n",
    "    tokenized_Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sizes ;  X : 11355, Y : 11355\n",
      "val sizes ;  X : 1262, Y : 1262\n"
     ]
    }
   ],
   "source": [
    "train_val_split = 0.9\n",
    "l = len(tokenized_X)\n",
    "split_idx = int(train_val_split * l)\n",
    "\n",
    "idxes = np.arange(l)\n",
    "r = np.random.permutation(idxes)\n",
    "\n",
    "train_idxs = r[:split_idx]\n",
    "val_idxs = r[split_idx:]\n",
    "\n",
    "train_X, train_Y = [], []\n",
    "val_X, val_Y = [], []\n",
    "\n",
    "\n",
    "for idx in train_idxs:\n",
    "    train_X.append(tokenized_X[idx])\n",
    "    train_Y.append(tokenized_Y[idx])\n",
    "    \n",
    "for idx in val_idxs:\n",
    "    val_X.append(tokenized_X[idx])\n",
    "    val_Y.append(tokenized_Y[idx])   \n",
    "    \n",
    "print(f\"train sizes ;  X : {len(train_X)}, Y : {len(train_Y)}\")\n",
    "print(f\"val sizes ;  X : {len(val_X)}, Y : {len(val_Y)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "NHWqg-w4nOtm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomAADataset(Dataset):\n",
    "  def __init__(self, X, Y, max_length=512, max_length2=32):\n",
    "    self.max_length = max_length\n",
    "    self.max_length2 = max_length2 \n",
    "    self.X = X\n",
    "    self.Y = Y\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    input_tokens = self.X[idx]\n",
    "    output_tokens = self.Y[idx]\n",
    "\n",
    "    # Pad input and output tokens\n",
    "    input_tokens = input_tokens + [0] * (self.max_length - len(input_tokens))\n",
    "\n",
    "    output_tokens = output_tokens + [0] * (self.max_length2 - len(output_tokens))\n",
    "\n",
    "    return {\"input_ids\": torch.tensor(input_tokens, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(output_tokens, dtype=torch.long),\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "0BpdFHmUtpda",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "from datasets import Dataset as Dataset_hf\n",
    "\n",
    "dataset = Dataset_hf.from_dict({\"source\": dataframe[\"Sequence\"].values, \"target\": dataframe[\"Protein Name\"].values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "kQv4-09StvBR",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  1, 118,  99,  85,  88,  89,  87, 100,  89,  88,  89,  90, 109,  88,\n",
       "         116,  89,  90,  85,  89, 108,  90, 108,  92, 100, 108,  92, 104, 110,\n",
       "         108, 101,  85,  92, 100, 100, 100, 108, 100, 108, 100, 101, 100, 108,\n",
       "         100, 100, 100, 100,  87,  89, 116, 116, 115,  85, 100, 116,  90,  85,\n",
       "         116,  88,  92,  85, 116, 101,  87,  89, 204,  92,  92, 101,  87,  85,\n",
       "          88,  89, 100, 129, 110, 100,  92,  92,  92,  92,  88,  90, 108,  88,\n",
       "          90, 100, 115,  92, 109, 104, 115,  89,  87,  88,  88,  89,  90,  87,\n",
       "          87,  87,  90, 100, 108,  87,  89, 116,  88,  87, 104,  88,  88, 131,\n",
       "          90, 131, 110,  87,  85, 110, 109, 118,  87, 110,  85, 116,  99,  88,\n",
       "         129, 104,  89,  85, 109,  85,  90,  92, 110, 111,  87, 115, 110,  90,\n",
       "          92,  89, 115,  88, 131, 131,  89,  89, 104, 115,  88,  87, 204, 116,\n",
       "          99,  90, 110,  89, 129,  99,  85,  90,  85,  99, 108, 111, 115, 101,\n",
       "         104, 110,  88,  89, 100,  88,  92, 129,  88,  92, 104,  92,  99, 131,\n",
       "         204,  90,  85, 108,  88,  87,  90, 116, 108, 118, 115, 108,  99,  92,\n",
       "          90, 115,  85,  89,  89,  89, 104,  89, 115, 104,  89, 129, 116,  85,\n",
       "         109,  88,  92,  87, 129,  85,  88, 129,  88, 115,  88,  85,  88,  87,\n",
       "          87, 129,  87,  87,  85, 129,  99,  88, 129,  88,  92,  88,  85,  85,\n",
       "          92,  87,  88,  87,  88,  88, 116,  88, 101,  88,  92,  87, 131,  88,\n",
       "          99, 109,  87,  88,  92,  89, 111,  88, 131,  87,  85,  85, 129,  88,\n",
       "         129,  88,  85,  89, 131,  85,  85,  85,  90,  87,  88, 101, 131,  87,\n",
       "          92,  87,  88, 104, 104,  87, 100,  92,  87, 108,  85,  87, 109,  88,\n",
       "          87,  88, 115,  88, 111, 111,  90,  88, 129,  85, 101,  85,  90,  85,\n",
       "          92,  89,  89,  87,  89, 101, 204,  89,  89, 129,  89, 100,  87, 108,\n",
       "          87,  90,  85,  90,  87,  85,  89, 101,  85, 111, 104,  92,  90,  92,\n",
       "         100,  89, 101, 116,  92,  85,  89,  89, 101, 111,  88,  89,  88,  89,\n",
       "          92,  87, 109,  87, 109, 111,  90,  90, 108, 129, 116,  87, 111, 111,\n",
       "         110,  88, 104,  88,  85,  88,  85, 111, 111, 104, 111,  88,  88,  88,\n",
       "          85,  85,  85,  92, 116, 115, 111,  90,  99,  90,  90,  90, 110,  89,\n",
       "          89, 109,  87,  88, 109,  87,  87,  85,  88,  88,  89,  87,  89, 111,\n",
       "         204,  87,  92, 109, 111,  89,  88,  89,  89,  89, 111,   2,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " 'labels': tensor([    1,  1607,  1265,   107, 18381,   591,    80,     2,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = CustomAADataset(train_X, train_Y, max_length_inp, max_length_out)\n",
    "val_dataset = CustomAADataset(val_X, val_Y, max_length_inp, max_length_out)\n",
    "\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad4e70280db433aadcf6b11fd534d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/1.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=None, padding=True, max_length=512)\n",
    "\n",
    "# Load T5 model\n",
    "config = T5Config.from_pretrained(\"mlewand/PROT5-small\")\n",
    "model = T5ForConditionalGeneration(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=None, padding=True, max_length=512)\n",
    "\n",
    "# Load T5 model\n",
    "#config = T5Config.from_pretrained(\"mlewand/PROT5-small\")\n",
    "#model = T5ForConditionalGeneration(config)\n",
    "model_name = \"t5-small\"\n",
    "config = T5Config.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name, config=config, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dats = None\n",
    "eval_d = None\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"\n",
    "    Original Trainer may have a memory leak. \n",
    "    This is a workaround to avoid storing too many tensors that are not needed.\n",
    "    \"\"\"\n",
    "    global dats\n",
    "    pred_ids = torch.argmax(logits[0],dim=-1)\n",
    "    return pred_ids\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    global eval_d\n",
    "    eval_d = pred\n",
    "    labels = pred.label_ids\n",
    "    # labels = np.argmax(labels, axis=1)\n",
    "    preds = pred.predictions\n",
    "\n",
    "    tot = np.sum(labels != 0) + 1e-10\n",
    "    classified_correctly = 0\n",
    "    exact_matches = 0\n",
    "    for i in range(preds.shape[0]):\n",
    "        mask = preds[i, :] != 0\n",
    "        classified_correctly += np.sum(preds[i, mask] == labels[i, mask])\n",
    "        exact_matches += np.all(preds[i,:] == labels[i, :])\n",
    "            \n",
    "    return {\"matches\": classified_correctly / tot, \"exact_matches\" : exact_matches / preds.shape[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35500' max='35500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35500/35500 49:54, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Exact Matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.385100</td>\n",
       "      <td>1.210753</td>\n",
       "      <td>0.389653</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.159100</td>\n",
       "      <td>1.115095</td>\n",
       "      <td>0.437474</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.087000</td>\n",
       "      <td>1.107715</td>\n",
       "      <td>0.409226</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.034000</td>\n",
       "      <td>1.035388</td>\n",
       "      <td>0.444985</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.992300</td>\n",
       "      <td>1.007090</td>\n",
       "      <td>0.444774</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.955400</td>\n",
       "      <td>0.966385</td>\n",
       "      <td>0.471646</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.922400</td>\n",
       "      <td>0.935863</td>\n",
       "      <td>0.492488</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.896100</td>\n",
       "      <td>0.917027</td>\n",
       "      <td>0.500212</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.871300</td>\n",
       "      <td>0.902732</td>\n",
       "      <td>0.509733</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.851500</td>\n",
       "      <td>0.887842</td>\n",
       "      <td>0.508570</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.833100</td>\n",
       "      <td>0.873111</td>\n",
       "      <td>0.513542</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.862447</td>\n",
       "      <td>0.519996</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>0.854010</td>\n",
       "      <td>0.521054</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.785300</td>\n",
       "      <td>0.849726</td>\n",
       "      <td>0.520102</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.773200</td>\n",
       "      <td>0.841855</td>\n",
       "      <td>0.526661</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.760900</td>\n",
       "      <td>0.834518</td>\n",
       "      <td>0.531634</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.749700</td>\n",
       "      <td>0.830319</td>\n",
       "      <td>0.531528</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.738900</td>\n",
       "      <td>0.825816</td>\n",
       "      <td>0.531951</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.729200</td>\n",
       "      <td>0.820125</td>\n",
       "      <td>0.534596</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.720400</td>\n",
       "      <td>0.814307</td>\n",
       "      <td>0.542848</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.711100</td>\n",
       "      <td>0.816410</td>\n",
       "      <td>0.536712</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.701300</td>\n",
       "      <td>0.811277</td>\n",
       "      <td>0.541790</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.694600</td>\n",
       "      <td>0.811513</td>\n",
       "      <td>0.542848</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.686100</td>\n",
       "      <td>0.808369</td>\n",
       "      <td>0.544435</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.806443</td>\n",
       "      <td>0.548244</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.674300</td>\n",
       "      <td>0.800994</td>\n",
       "      <td>0.546974</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.666400</td>\n",
       "      <td>0.799936</td>\n",
       "      <td>0.546763</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.660800</td>\n",
       "      <td>0.795822</td>\n",
       "      <td>0.551100</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.655300</td>\n",
       "      <td>0.798108</td>\n",
       "      <td>0.551735</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.649500</td>\n",
       "      <td>0.797404</td>\n",
       "      <td>0.551629</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.643500</td>\n",
       "      <td>0.798976</td>\n",
       "      <td>0.551629</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.798666</td>\n",
       "      <td>0.550466</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.634800</td>\n",
       "      <td>0.796094</td>\n",
       "      <td>0.554274</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.629900</td>\n",
       "      <td>0.796608</td>\n",
       "      <td>0.555015</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.627300</td>\n",
       "      <td>0.791077</td>\n",
       "      <td>0.555015</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.622400</td>\n",
       "      <td>0.797202</td>\n",
       "      <td>0.556284</td>\n",
       "      <td>0.001585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.618600</td>\n",
       "      <td>0.795142</td>\n",
       "      <td>0.555438</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.614800</td>\n",
       "      <td>0.794496</td>\n",
       "      <td>0.557766</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.612200</td>\n",
       "      <td>0.794144</td>\n",
       "      <td>0.557237</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.608900</td>\n",
       "      <td>0.793198</td>\n",
       "      <td>0.557237</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.606300</td>\n",
       "      <td>0.796019</td>\n",
       "      <td>0.557871</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.604800</td>\n",
       "      <td>0.793199</td>\n",
       "      <td>0.558189</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.603100</td>\n",
       "      <td>0.791125</td>\n",
       "      <td>0.559458</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.599200</td>\n",
       "      <td>0.792691</td>\n",
       "      <td>0.557342</td>\n",
       "      <td>0.000792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.599400</td>\n",
       "      <td>0.793112</td>\n",
       "      <td>0.558400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.595600</td>\n",
       "      <td>0.794400</td>\n",
       "      <td>0.557660</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.595900</td>\n",
       "      <td>0.794013</td>\n",
       "      <td>0.558400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.593700</td>\n",
       "      <td>0.793718</td>\n",
       "      <td>0.558400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.592400</td>\n",
       "      <td>0.793302</td>\n",
       "      <td>0.558506</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.592700</td>\n",
       "      <td>0.793019</td>\n",
       "      <td>0.558718</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=35500, training_loss=0.7375330303353324, metrics={'train_runtime': 2994.8567, 'train_samples_per_second': 189.575, 'train_steps_per_second': 11.854, 'total_flos': 7.6840307785728e+16, 'train_loss': 0.7375330303353324, 'epoch': 50.0})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"PROT5-small\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=50,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    fp16=True,  # Enable mixed precision training if your GPU supports it\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=None,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics= preprocess_logits_for_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(\"mlewand/PROT5-small-correct-eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = eval_d.label_ids\n",
    "    # labels = np.argmax(labels, axis=1)\n",
    "preds = eval_d.predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00017333597464342314"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 0\n",
    "for a,b in zip(labels,preds):\n",
    "    mask = a != 0\n",
    "    k += np.sum(a[mask] ==b[mask])\n",
    "k / np.sum(labels != 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0de8bb85911b427d8294a81d94939ce4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cd698668f6984461956d307c4cbce5cc",
       "IPY_MODEL_99170237c3444b13a432b8c374fc1473",
       "IPY_MODEL_43cf4edef7a043928b9508bde88b9374"
      ],
      "layout": "IPY_MODEL_443cfdca91394190a0c800b1e1e654eb"
     }
    },
    "2106053b50d844a5a4b0b466a5614841": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fe2f7b256874bf384386a4fa5123ea3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d217e7538a049be9fb50bacf859e9ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43cf4edef7a043928b9508bde88b9374": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d217e7538a049be9fb50bacf859e9ac",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2fe2f7b256874bf384386a4fa5123ea3",
      "value": " 0/198 [00:00&lt;?, ?it/s]"
     }
    },
    "443cfdca91394190a0c800b1e1e654eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71b09a2f29c44961b792ddf69ea8f150": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "971715e9020f4f68ab3a4f024c7e85bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "99170237c3444b13a432b8c374fc1473": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2106053b50d844a5a4b0b466a5614841",
      "max": 198,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_971715e9020f4f68ab3a4f024c7e85bb",
      "value": 0
     }
    },
    "99599d201e274dacb4d8c0dc8ffb80b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd698668f6984461956d307c4cbce5cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71b09a2f29c44961b792ddf69ea8f150",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_99599d201e274dacb4d8c0dc8ffb80b9",
      "value": "  0%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
