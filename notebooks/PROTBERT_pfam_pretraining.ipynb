{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDWOMAUVT_9r"
   },
   "source": [
    "# install dependecnies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MahFUTFSUCFq",
    "outputId": "b3df2c55-fcdd-4109-939e-c1a93e00499b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q datasets\n",
    "!pip install -q transformers\n",
    "!pip install -q umap-learn\n",
    "!pip install -q bertviz\n",
    "!pip install -q accelerate\n",
    "!pip install -q seqeval\n",
    "!pip install -q tqdm\n",
    "!pip install -q scikit-learn \n",
    "!pip install -q transformers\n",
    "!pip install -q huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Detected operating system as Ubuntu/focal.\n",
      "Checking for curl...\n",
      "Detected curl...\n",
      "Checking for gpg...\n",
      "Detected gpg...\n",
      "Detected apt version as 2.0.9\n",
      "Running apt-get update... done.\n",
      "Installing apt-transport-https... done.\n",
      "Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n",
      "Importing packagecloud gpg key... Packagecloud gpg key imported to /etc/apt/keyrings/github_git-lfs-archive-keyring.gpg\n",
      "done.\n",
      "Running apt-get update... done.\n",
      "\n",
      "The repository is setup! You can now install packages.\n"
     ]
    }
   ],
   "source": [
    "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "git: 'lfs' is not a git command. See 'git --help'.\n",
      "\n",
      "The most similar command is\n",
      "\tlog\n"
     ]
    }
   ],
   "source": [
    "!git lfs install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5326d0be6f34b7a809d0acd13c02aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k__0_zfTUFhO"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oRdkAUW4UGeK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csv7zY2CUIEe"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUlxWWcXUJNq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_id = '1w3IQMK3PmXH-Bq6Lt_P8wxGPvr5olrZT'\n",
    "destination = 'pfam.zip'\n",
    "hf_name = \"t5-small\"\n",
    "n_families_of_interest = 1000\n",
    "data_dirpath = \"pfam\"\n",
    "aminoacid_separate_by = \"\"\n",
    "max_length = 512\n",
    "tokenizer_folder = \"PROTNAME_tok\"\n",
    "save_folder = \"PROTNAME\"\n",
    "vocab_size=32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFjUpTN8UNyS"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40KG3kyHUOtM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_size(value):\n",
    "  if value >= 1024**3:\n",
    "    return f\"{round(value / 1024**3 , 3)} GB\"\n",
    "  elif value >= 1024**2:\n",
    "    return f\"{round(value / 1024**2 , 3)} MB\"\n",
    "  elif value >= 1024:\n",
    "    return f\"{round(value / 1024 , 3)} KB\"\n",
    "  return f\"{value} B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DAYQ7M_TUPMr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code taken from https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "    params = { 'id' : id, 'confirm' : 1 }\n",
    "    response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "    \n",
    "    pb = tqdm.tqdm(response.iter_content(CHUNK_SIZE))\n",
    "    b_total = 0\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for i,chunk in enumerate(pb):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "                b_total += len(chunk)\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                  pb.set_description(f\"written : {format_size(b_total)}\")\n",
    "                i += 1\n",
    "    print(\"\\n\")\n",
    "    print(f\"saved all the data to {destination}. total size : {format_size(os.stat(destination).st_size)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5n-nQBqwTA7L"
   },
   "source": [
    "# Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTAn0zO0S8qL",
    "outputId": "69e5937c-0f2e-404a-bcdf-f1d9ad2d139c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "written : 468.781 MB: : 15780it [00:10, 1503.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "saved all the data to pfam.zip. total size : 493.095 MB\n"
     ]
    }
   ],
   "source": [
    "download_file_from_google_drive(file_id, destination)\n",
    "with zipfile.ZipFile(destination, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\".\")\n",
    "!mv random_split pfam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20iK8FX3UnTN"
   },
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CEkQLYGDTw2a",
    "outputId": "9dd2e95c-6bd7-45b9-e571-ad8db3bac2a4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available dataset partitions:  ['train', 'test', 'random_split', 'dev']\n",
      "Dataset partition \"test\" has 126171 sequences\n",
      "Dataset partition \"dev\" has 126171 sequences\n",
      "Dataset partition \"train\" has 1086741 sequences\n",
      "how many labels : 17929\n",
      "1000 classes is 40.400000000000006 portion of training data\n"
     ]
    }
   ],
   "source": [
    "def read_all_shards(partition='dev', data_dir = data_dirpath):\n",
    "    shards = []\n",
    "    for fn in os.listdir(os.path.join(data_dir, partition)):\n",
    "        with open(os.path.join(data_dir, partition, fn)) as f:\n",
    "            shards.append(pd.read_csv(f, index_col=None))\n",
    "    \n",
    "    return pd.concat(shards)\n",
    "\n",
    "def read_all_data_initial():\n",
    "  global train, test, dev, all_train_ds_size, all_test_ds_size, all_dev_ds_size\n",
    "\n",
    "  test = read_all_shards('test')\n",
    "  dev = read_all_shards('dev')\n",
    "  train = read_all_shards('train')\n",
    "\n",
    "  partitions = {'test': test, 'dev': dev, 'train': train}\n",
    "  for name, df in partitions.items():\n",
    "      print('Dataset partition \"%s\" has %d sequences' % (name, len(df)))\n",
    "\n",
    "  all_train_ds_size = len(train)\n",
    "  all_test_ds_size = len(test)\n",
    "  all_dev_ds_size = len(dev)\n",
    "\n",
    "  train.reset_index(inplace=True, drop=True)\n",
    "  dev.reset_index(inplace=True, drop=True)\n",
    "  test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "def get_cumulative(data):\n",
    "    counter = Counter(data['family_accession'])\n",
    "    print(f\"how many labels : {len(counter)}\")\n",
    "    \n",
    "    datasetSize = len(data)\n",
    "    xs = []\n",
    "    x_labels = []\n",
    "    ys = []\n",
    "\n",
    "    t = 0\n",
    "    cumulative = []\n",
    "\n",
    "    for i,(x, y) in  enumerate(counter.most_common()):\n",
    "        xs.append(i)\n",
    "        x_labels.append(x)\n",
    "        ys.append(y)\n",
    "        t += y / datasetSize\n",
    "        cumulative.append(t)\n",
    "    return cumulative\n",
    "\n",
    "\n",
    "# EXECUTION CODE\n",
    "print('Available dataset partitions: ', os.listdir(data_dirpath))\n",
    "read_all_data_initial()\n",
    "cumulative = get_cumulative(train)\n",
    "print(f\"{n_families_of_interest} classes is {100 * round( cumulative[n_families_of_interest-1],3)} portion of training data\")\n",
    "\n",
    "familiesOfInterest = train.family_accession.value_counts()[:n_families_of_interest]\n",
    "\n",
    "mask = train.family_accession.isin(familiesOfInterest.index.values)\n",
    "train = train.loc[mask,:]\n",
    "\n",
    "mask = dev.family_accession.isin(familiesOfInterest.index.values)\n",
    "dev = dev.loc[mask,:]\n",
    "\n",
    "mask = test.family_accession.isin(familiesOfInterest.index.values)\n",
    "test = test.loc[mask,:]\n",
    "\n",
    "\n",
    "################################################################################\n",
    "train_seq = train['sequence']\n",
    "dev_seq = dev['sequence']\n",
    "test_seq = test['sequence']\n",
    "\n",
    "################################################################################\n",
    "train_sentences = train_seq.apply(lambda seq: aminoacid_separate_by.join([aa for aa in seq]))\n",
    "validation_sentences = dev_seq.apply(lambda seq: aminoacid_separate_by.join([aa for aa in seq]))\n",
    "test_sentences = test_seq.apply(lambda seq: aminoacid_separate_by.join([aa for aa in seq]))\n",
    "\n",
    "################################################################################\n",
    "train_labels = train['family_accession'].apply(lambda x: x.split('.')[0])\n",
    "validation_labels = dev['family_accession'].apply(lambda x: x.split('.')[0])\n",
    "test_labels = test['family_accession'].apply(lambda x: x.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41vNsN2SWUf3",
    "outputId": "17158e40-e648-437c-f4a7-f7020810bb83",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          RIGIMTSGGDAPGMNLAIRAVARKALSSGLEAYGINYGFAGLVAGD...\n",
       "4          SLWNILKKNIGKDLSKVAMPVTLNEPLNALQLLCEELEYSELLDDA...\n",
       "7          FFGDVVGKPGRAAVLEHLPELRVRLRLDFVVVNGENAAGGFGLTRQ...\n",
       "9          SDVRDMTPDQLQDELLKLKKTQFNLRFQGASGQLEKVHQMRQVRRD...\n",
       "10                                      SLKFLNFAQNEFNGSIPESV\n",
       "                                 ...                        \n",
       "1086720    VLDIGCGNGKITAQIAERVPAGAVLGIDSSEQMISFASSHFAPADW...\n",
       "1086724    LSVGLGCNRGTPAKAFEVAVTELFYDSSLNLQSIRNFASIDLKSDE...\n",
       "1086729    QDWVASVSEPWLMLTPANGVGSTTGTVKIDTTLMSGRRTTDVAFLG...\n",
       "1086735    DRIVAMSTISPIIAVVLALWSLEMRRGIYLDIALVLALLDFIMVVA...\n",
       "1086738    ERLMPAFTGLSGSGIAYVLSFLHGMALAGTMAGIPYTESLRIVEAL...\n",
       "Name: sequence, Length: 439493, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WxKz_vnFcAY0",
    "outputId": "de03abb8-2b69-40c8-c118-5a7fcd288df1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 439493/439493 [00:00<00:00, 2166712.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "labels = set()\n",
    "\n",
    "for v in tqdm.tqdm(train_labels):\n",
    "  labels.add(v)\n",
    "\n",
    "label_to_id = {k:v for v,k in enumerate(labels)}\n",
    "\n",
    "print()\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0u9LshmcikE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels_as_int = train_labels.map(label_to_id)\n",
    "val_labels_as_int = validation_labels.map(label_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSFxP3eydihN",
    "outputId": "72ae0f58-18c1-43d3-d6c8-3d6104d191e2",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_labels_as_int.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YA_6yOe3bxML",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_dict({\"sentence\": train_sentences, \"labels\": train_labels_as_int})\n",
    "dataset_val = Dataset.from_dict({\"sentence\": validation_sentences, \"labels\": val_labels_as_int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ASspYuGYeDer",
    "outputId": "dbb53459-df10-4b1c-dce2-9ab8ff019d5f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'labels'],\n",
       "    num_rows: 439493\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hL3JiLZ_YJMs",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "# Customize training\n",
    "\n",
    "tokenizer.train_from_iterator(iter(train_sentences), vocab_size=vocab_size, min_frequency=2, special_tokens=[\n",
    "    \"<s>\",\n",
    "    \"<pad>\",\n",
    "    \"</s>\",\n",
    "    \"<unk>\",\n",
    "    \"<mask>\",\n",
    "])\n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")\n",
    "tokenizer.enable_truncation(max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k63Zdb68XQEW",
    "outputId": "9dceb6a5-fdbb-45cd-93d5-ac3b6180f929",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PROTNAME_tok/vocab.json', 'PROTNAME_tok/merges.txt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!mkdir {tokenizer_folder}\n",
    "tokenizer.save_model(tokenizer_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bTLXACRuXpIc",
    "outputId": "02011107-b240-414f-fbc4-474595e86732",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datapoint : RIGIMTSGGDAPGMNLAIRAVARKALSSGLEAYGINYGFAGLVAGDIHEFKAADLDDMVSQGGTMLYSARYPEFAQEESQLKGIEQLKKFGIDALVVIGGDGSYHGALRLTEHGYNTIGLPGTIDNDIPFTDFTIGFDTALNTAVDAIDKIRDTAKSHQRVFAVQVMGRNAADIALWAGVASGADAVIAPGFDYDVEAIANKLKKNRANGKDYGIIVIAEGDANSDAAPEFIDQLKQYGDFDARATVIGHVQRGGVPSAKDRVLASKMGAYAVELL, len(276)\n",
      "Encoding(num_tokens=278, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n"
     ]
    }
   ],
   "source": [
    "datapoint = train_sentences.iloc[0]\n",
    "encoded = tokenizer.encode(datapoint) \n",
    "print(f\"datapoint : {datapoint}, len({len(datapoint)})\")\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XYmIxnH_jsH4",
    "outputId": "b3d3ac22-b8b3-402d-c6b4-790defb3f2cf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 54, 45, 43, 45, 49, 56, 55, 43, 43, 40, 37, 52, 43, 49, 50, 48, 37, 45, 54, 37, 58, 37, 54, 47, 37, 48, 55, 55, 43, 48, 41, 37, 61, 43, 45, 50, 61, 43, 42, 37, 43, 48, 58, 37, 43, 40, 45, 44, 41, 42, 47, 37, 37, 40, 48, 40, 40, 49, 58, 55, 53, 43, 43, 56, 49, 48, 61, 55, 37, 54, 61, 52, 41, 42, 37, 53, 41, 41, 55, 53, 48, 47, 43, 45, 41, 53, 48, 47, 47, 42, 43, 45, 40, 37, 48, 58, 58, 45, 43, 43, 40, 43, 55, 61, 44, 43, 37, 48, 54, 48, 56, 41, 44, 43, 61, 50, 56, 45, 43, 48, 52, 43, 56, 45, 40, 50, 40, 45, 52, 42, 56, 40, 42, 56, 45, 43, 42, 40, 56, 37, 48, 50, 56, 37, 58, 40, 37, 45, 40, 47, 45, 54, 40, 56, 37, 47, 55, 44, 53, 54, 58, 42, 37, 58, 53, 58, 49, 43, 54, 50, 37, 37, 40, 45, 37, 48, 59, 37, 43, 58, 37, 55, 43, 37, 40, 37, 58, 45, 37, 52, 43, 42, 40, 61, 40, 58, 41, 37, 45, 37, 50, 47, 48, 47, 47, 50, 54, 37, 50, 43, 47, 40, 61, 43, 45, 45, 58, 45, 37, 41, 43, 40, 37, 50, 55, 40, 37, 37, 52, 41, 42, 45, 40, 53, 48, 47, 53, 61, 43, 40, 42, 40, 37, 54, 37, 56, 58, 45, 43, 44, 58, 53, 54, 43, 43, 58, 52, 55, 37, 47, 40, 54, 58, 48, 37, 55, 47, 49, 43, 37, 61, 37, 58, 41, 48, 48, 2]\n"
     ]
    }
   ],
   "source": [
    "print(encoded.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EeA5HK8BhHOx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4OljxIdeYkKu",
    "outputId": "dff04077-cfa9-4f2e-a392-072c9261bd94",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Sun Apr 23 20:29:55 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.85.05    Driver Version: 525.85.05    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:82:00.0 Off |                  Off |\n",
      "|  0%   31C    P8    18W / 450W |      1MiB / 24564MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that we have a GPU\n",
    "!nvidia-smi\n",
    "# Check that PyTorch sees it\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "68ceefa838d249728214063ae966d729",
      "623cc33375724894904a17b6b9205a40",
      "120c4ab1ceba4894abde7e5221ef485a",
      "916865c05909423d8e091831181cf179",
      "1aa0794888c544a9a2fe2ba12270a026",
      "0c009c720e2543dca61436b863e0274e",
      "7c7669385f954dcd8439853abd92e563",
      "a320cc1688cf4b35853a0d3dc4beae62",
      "1e8db3c3de98455bb956ba540618786d",
      "5bebcaca6caa451097cf048109382c79",
      "6550bc39149943e685da04a207b9aa96",
      "23c568c2d96c49c496ae9230408d6b51",
      "6bbe57a30e004d6080d4b3c2c5d13143",
      "89debd6374894997b2808b7380c53edb",
      "1b967ff03f894233a25a8d2df5e67951",
      "076b309701724dfcbbd47226366edf0c",
      "f27b9c1295ea4276abbae49c4ec7f1cd",
      "f2fa987f3cd14a41a7d0e61b10539af7",
      "55af7efcb22548029a860c61ab0c6d9d",
      "2c7ff0cef1b7494c83157c595d419ad0",
      "58268a88b46841d596a2256f4a87a80b",
      "a4d49f23e1c04f769d0d2b62fe38ec5b"
     ]
    },
    "id": "Nbc3ik9Hplvu",
    "outputId": "ac0d105d-1a5c-4e04-885c-e6cb3fd59ca8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/439493 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/54378 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_folder, max_len=max_length, padding=True)\n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
    "encoded_dataset_val = dataset_val.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VseUNi5MZh7P",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "config = BertConfig(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    max_position_embeddings=max_length+2,\n",
    "    hidden_size=128,\n",
    "    num_hidden_layers=2,\n",
    "    num_attention_heads=8,\n",
    "    type_vocab_size=1,\n",
    "    num_labels=n_families_of_interest+1\n",
    ")\n",
    "\n",
    "model = BertForSequenceClassification(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gxR65OMXjwbO",
    "outputId": "da78fe3f-8ae6-4237-ecbd-d6f2fe629638",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(261, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(514, 128)\n",
       "      (token_type_embeddings): Embedding(1, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-1): 2 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (key): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (value): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=128, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=128, bias=True)\n",
       "            (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=128, out_features=1001, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1ryKkoebCBS",
    "outputId": "d2f4744e-f1ed-4741-b7b8-8315ce59ba04",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8669214248657227"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters() / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpJ4-Sipn-VS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "  acc = accuracy_score(labels, preds)\n",
    "  return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_MwtPm4NbLWR",
    "outputId": "cd098e88-26f8-494a-acdc-4bb5f5491393",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17170' max='17170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17170/17170 37:04, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.624100</td>\n",
       "      <td>4.499508</td>\n",
       "      <td>0.072474</td>\n",
       "      <td>0.016205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.458200</td>\n",
       "      <td>4.376648</td>\n",
       "      <td>0.072511</td>\n",
       "      <td>0.017069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.356000</td>\n",
       "      <td>4.280637</td>\n",
       "      <td>0.089135</td>\n",
       "      <td>0.023998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.290300</td>\n",
       "      <td>4.231867</td>\n",
       "      <td>0.097668</td>\n",
       "      <td>0.029265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.254500</td>\n",
       "      <td>4.213886</td>\n",
       "      <td>0.099176</td>\n",
       "      <td>0.030066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17170, training_loss=4.396602108510484, metrics={'train_runtime': 2224.3062, 'train_samples_per_second': 987.933, 'train_steps_per_second': 7.719, 'total_flos': 1.2416350270311936e+16, 'train_loss': 4.396602108510484, 'epoch': 5.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=save_folder,\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=5e-4,\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir=os.path.join(save_folder, \"logs\"),            # directory for storing logs\n",
    "    logging_steps=50,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=False,\n",
    "    logging_strategy=\"epoch\",\n",
    "    bf16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset,\n",
    "    eval_dataset=encoded_dataset_val,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17170' max='17170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17170/17170 36:03, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.303800</td>\n",
       "      <td>0.859529</td>\n",
       "      <td>0.789143</td>\n",
       "      <td>0.780893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.911600</td>\n",
       "      <td>0.582967</td>\n",
       "      <td>0.861690</td>\n",
       "      <td>0.858216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.655700</td>\n",
       "      <td>0.422161</td>\n",
       "      <td>0.900474</td>\n",
       "      <td>0.898664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.494400</td>\n",
       "      <td>0.323402</td>\n",
       "      <td>0.923572</td>\n",
       "      <td>0.922270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.396600</td>\n",
       "      <td>0.273981</td>\n",
       "      <td>0.936886</td>\n",
       "      <td>0.935994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17170, training_loss=0.7524396999672394, metrics={'train_runtime': 2163.4732, 'train_samples_per_second': 1015.712, 'train_steps_per_second': 7.936, 'total_flos': 1.2416350270311936e+16, 'train_loss': 0.7524396999672394, 'epoch': 5.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=save_folder,\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=5e-4,\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir=os.path.join(save_folder, \"logs\"),            # directory for storing logs\n",
    "    logging_steps=50,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=False,\n",
    "    logging_strategy=\"epoch\",\n",
    "    bf16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset,\n",
    "    eval_dataset=encoded_dataset_val,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10302' max='10302' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10302/10302 21:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.368800</td>\n",
       "      <td>0.257706</td>\n",
       "      <td>0.939976</td>\n",
       "      <td>0.939266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.320600</td>\n",
       "      <td>0.240826</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.943806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.284300</td>\n",
       "      <td>0.226632</td>\n",
       "      <td>0.947166</td>\n",
       "      <td>0.946612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10302, training_loss=0.3245752801526706, metrics={'train_runtime': 1296.2348, 'train_samples_per_second': 1017.161, 'train_steps_per_second': 7.948, 'total_flos': 7448442657659136.0, 'train_loss': 0.3245752801526706, 'epoch': 3.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=save_folder,\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_dir=os.path.join(save_folder, \"logs\"),            # directory for storing logs\n",
    "    logging_steps=50,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=False,\n",
    "    logging_strategy=\"epoch\",\n",
    "    bf16=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset,\n",
    "    eval_dataset=encoded_dataset_val,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mlewand/PROTBERT/commit/5b8473c5e4e3ed0ca3528fe2d011d8b9710f5d84', commit_message='Upload tokenizer', commit_description='', oid='5b8473c5e4e3ed0ca3528fe2d011d8b9710f5d84', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub(\"PROTBERT\")\n",
    "tokenizer.push_to_hub(\"PROTBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mlewand/PROTBERT/commit/277712a4caacf06153faebfeaac18f80b39785f3', commit_message='Upload tokenizer', commit_description='', oid='277712a4caacf06153faebfeaac18f80b39785f3', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\"PROTBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datapoint : RIGIMTSGGDAPGMNLAIRAVARKALSSGLEAYGINYGFAGLVAGDIHEFKAADLDDMVSQGGTMLYSARYPEFAQEESQLKGIEQLKKFGIDALVVIGGDGSYHGALRLTEHGYNTIGLPGTIDNDIPFTDFTIGFDTALNTAVDAIDKIRDTAKSHQRVFAVQVMGRNAADIALWAGVASGADAVIAPGFDYDVEAIANKLKKNRANGKDYGIIVIAEGDANSDAAPEFIDQLKQYGDFDARATVIGHVQRGGVPSAKDRVLASKMGAYAVELL, len(276)\n"
     ]
    }
   ],
   "source": [
    "datapoint = train_sentences.iloc[0]\n",
    "encoded = tokenizer.encode(datapoint) \n",
    "print(f\"datapoint : {datapoint}, len({len(datapoint)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'RIGIMTSGGDAPGMNLAIRAVARKALSSGLEAYGINYGFAGLVAGDIHEFKAADLDDMVSQGGTMLYSARYPEFAQEESQLKGIEQLKKFGIDALVVIGGDGSYHGALRLTEHGYNTIGLPGTIDNDIPFTDFTIGFDTALNTAVDAIDKIRDTAKSHQRVFAVQVMGRNAADIALWAGVASGADAVIAPGFDYDVEAIANKLKKNRANGKDYGIIVIAEGDANSDAAPEFIDQLKQYGDFDARATVIGHVQRGGVPSAKDRVLASKMGAYAVELL',\n",
       " 'labels': 233,\n",
       " 'input_ids': [0,\n",
       "  54,\n",
       "  45,\n",
       "  43,\n",
       "  45,\n",
       "  49,\n",
       "  56,\n",
       "  55,\n",
       "  43,\n",
       "  43,\n",
       "  40,\n",
       "  37,\n",
       "  52,\n",
       "  43,\n",
       "  49,\n",
       "  50,\n",
       "  48,\n",
       "  37,\n",
       "  45,\n",
       "  54,\n",
       "  37,\n",
       "  58,\n",
       "  37,\n",
       "  54,\n",
       "  47,\n",
       "  37,\n",
       "  48,\n",
       "  55,\n",
       "  55,\n",
       "  43,\n",
       "  48,\n",
       "  41,\n",
       "  37,\n",
       "  61,\n",
       "  43,\n",
       "  45,\n",
       "  50,\n",
       "  61,\n",
       "  43,\n",
       "  42,\n",
       "  37,\n",
       "  43,\n",
       "  48,\n",
       "  58,\n",
       "  37,\n",
       "  43,\n",
       "  40,\n",
       "  45,\n",
       "  44,\n",
       "  41,\n",
       "  42,\n",
       "  47,\n",
       "  37,\n",
       "  37,\n",
       "  40,\n",
       "  48,\n",
       "  40,\n",
       "  40,\n",
       "  49,\n",
       "  58,\n",
       "  55,\n",
       "  53,\n",
       "  43,\n",
       "  43,\n",
       "  56,\n",
       "  49,\n",
       "  48,\n",
       "  61,\n",
       "  55,\n",
       "  37,\n",
       "  54,\n",
       "  61,\n",
       "  52,\n",
       "  41,\n",
       "  42,\n",
       "  37,\n",
       "  53,\n",
       "  41,\n",
       "  41,\n",
       "  55,\n",
       "  53,\n",
       "  48,\n",
       "  47,\n",
       "  43,\n",
       "  45,\n",
       "  41,\n",
       "  53,\n",
       "  48,\n",
       "  47,\n",
       "  47,\n",
       "  42,\n",
       "  43,\n",
       "  45,\n",
       "  40,\n",
       "  37,\n",
       "  48,\n",
       "  58,\n",
       "  58,\n",
       "  45,\n",
       "  43,\n",
       "  43,\n",
       "  40,\n",
       "  43,\n",
       "  55,\n",
       "  61,\n",
       "  44,\n",
       "  43,\n",
       "  37,\n",
       "  48,\n",
       "  54,\n",
       "  48,\n",
       "  56,\n",
       "  41,\n",
       "  44,\n",
       "  43,\n",
       "  61,\n",
       "  50,\n",
       "  56,\n",
       "  45,\n",
       "  43,\n",
       "  48,\n",
       "  52,\n",
       "  43,\n",
       "  56,\n",
       "  45,\n",
       "  40,\n",
       "  50,\n",
       "  40,\n",
       "  45,\n",
       "  52,\n",
       "  42,\n",
       "  56,\n",
       "  40,\n",
       "  42,\n",
       "  56,\n",
       "  45,\n",
       "  43,\n",
       "  42,\n",
       "  40,\n",
       "  56,\n",
       "  37,\n",
       "  48,\n",
       "  50,\n",
       "  56,\n",
       "  37,\n",
       "  58,\n",
       "  40,\n",
       "  37,\n",
       "  45,\n",
       "  40,\n",
       "  47,\n",
       "  45,\n",
       "  54,\n",
       "  40,\n",
       "  56,\n",
       "  37,\n",
       "  47,\n",
       "  55,\n",
       "  44,\n",
       "  53,\n",
       "  54,\n",
       "  58,\n",
       "  42,\n",
       "  37,\n",
       "  58,\n",
       "  53,\n",
       "  58,\n",
       "  49,\n",
       "  43,\n",
       "  54,\n",
       "  50,\n",
       "  37,\n",
       "  37,\n",
       "  40,\n",
       "  45,\n",
       "  37,\n",
       "  48,\n",
       "  59,\n",
       "  37,\n",
       "  43,\n",
       "  58,\n",
       "  37,\n",
       "  55,\n",
       "  43,\n",
       "  37,\n",
       "  40,\n",
       "  37,\n",
       "  58,\n",
       "  45,\n",
       "  37,\n",
       "  52,\n",
       "  43,\n",
       "  42,\n",
       "  40,\n",
       "  61,\n",
       "  40,\n",
       "  58,\n",
       "  41,\n",
       "  37,\n",
       "  45,\n",
       "  37,\n",
       "  50,\n",
       "  47,\n",
       "  48,\n",
       "  47,\n",
       "  47,\n",
       "  50,\n",
       "  54,\n",
       "  37,\n",
       "  50,\n",
       "  43,\n",
       "  47,\n",
       "  40,\n",
       "  61,\n",
       "  43,\n",
       "  45,\n",
       "  45,\n",
       "  58,\n",
       "  45,\n",
       "  37,\n",
       "  41,\n",
       "  43,\n",
       "  40,\n",
       "  37,\n",
       "  50,\n",
       "  55,\n",
       "  40,\n",
       "  37,\n",
       "  37,\n",
       "  52,\n",
       "  41,\n",
       "  42,\n",
       "  45,\n",
       "  40,\n",
       "  53,\n",
       "  48,\n",
       "  47,\n",
       "  53,\n",
       "  61,\n",
       "  43,\n",
       "  40,\n",
       "  42,\n",
       "  40,\n",
       "  37,\n",
       "  54,\n",
       "  37,\n",
       "  56,\n",
       "  58,\n",
       "  45,\n",
       "  43,\n",
       "  44,\n",
       "  58,\n",
       "  53,\n",
       "  54,\n",
       "  43,\n",
       "  43,\n",
       "  58,\n",
       "  52,\n",
       "  55,\n",
       "  37,\n",
       "  47,\n",
       "  40,\n",
       "  54,\n",
       "  58,\n",
       "  48,\n",
       "  37,\n",
       "  55,\n",
       "  47,\n",
       "  49,\n",
       "  43,\n",
       "  37,\n",
       "  61,\n",
       "  37,\n",
       "  58,\n",
       "  41,\n",
       "  48,\n",
       "  48,\n",
       "  2],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "076b309701724dfcbbd47226366edf0c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "0c009c720e2543dca61436b863e0274e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "120c4ab1ceba4894abde7e5221ef485a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a320cc1688cf4b35853a0d3dc4beae62",
      "max": 439493,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1e8db3c3de98455bb956ba540618786d",
      "value": 439493
     }
    },
    "1aa0794888c544a9a2fe2ba12270a026": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": "hidden",
      "width": null
     }
    },
    "1b967ff03f894233a25a8d2df5e67951": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58268a88b46841d596a2256f4a87a80b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a4d49f23e1c04f769d0d2b62fe38ec5b",
      "value": " 54000/54378 [00:06&lt;00:00, 8160.23 examples/s]"
     }
    },
    "1e8db3c3de98455bb956ba540618786d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "23c568c2d96c49c496ae9230408d6b51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6bbe57a30e004d6080d4b3c2c5d13143",
       "IPY_MODEL_89debd6374894997b2808b7380c53edb",
       "IPY_MODEL_1b967ff03f894233a25a8d2df5e67951"
      ],
      "layout": "IPY_MODEL_076b309701724dfcbbd47226366edf0c"
     }
    },
    "2c7ff0cef1b7494c83157c595d419ad0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "55af7efcb22548029a860c61ab0c6d9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58268a88b46841d596a2256f4a87a80b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bebcaca6caa451097cf048109382c79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "623cc33375724894904a17b6b9205a40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c009c720e2543dca61436b863e0274e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7c7669385f954dcd8439853abd92e563",
      "value": "Map: 100%"
     }
    },
    "6550bc39149943e685da04a207b9aa96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "68ceefa838d249728214063ae966d729": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_623cc33375724894904a17b6b9205a40",
       "IPY_MODEL_120c4ab1ceba4894abde7e5221ef485a",
       "IPY_MODEL_916865c05909423d8e091831181cf179"
      ],
      "layout": "IPY_MODEL_1aa0794888c544a9a2fe2ba12270a026"
     }
    },
    "6bbe57a30e004d6080d4b3c2c5d13143": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f27b9c1295ea4276abbae49c4ec7f1cd",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f2fa987f3cd14a41a7d0e61b10539af7",
      "value": "Map:  99%"
     }
    },
    "7c7669385f954dcd8439853abd92e563": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89debd6374894997b2808b7380c53edb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55af7efcb22548029a860c61ab0c6d9d",
      "max": 54378,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2c7ff0cef1b7494c83157c595d419ad0",
      "value": 54378
     }
    },
    "916865c05909423d8e091831181cf179": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5bebcaca6caa451097cf048109382c79",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6550bc39149943e685da04a207b9aa96",
      "value": " 439000/439493 [00:55&lt;00:00, 8912.88 examples/s]"
     }
    },
    "a320cc1688cf4b35853a0d3dc4beae62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a4d49f23e1c04f769d0d2b62fe38ec5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f27b9c1295ea4276abbae49c4ec7f1cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2fa987f3cd14a41a7d0e61b10539af7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
