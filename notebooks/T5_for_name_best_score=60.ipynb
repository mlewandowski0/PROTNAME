{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KMTa-R8A6jiI",
    "outputId": "268501f2-cc48-4b81-d027-87d5ae402d45",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"\\x1b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\\x1b[0m\\x1b[33m\",\n",
       " '\\x1b[0m',\n",
       " '\\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m A new release of pip is available: \\x1b[0m\\x1b[31;49m23.0.1\\x1b[0m\\x1b[39;49m -> \\x1b[0m\\x1b[32;49m23.1.2\\x1b[0m',\n",
       " '\\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m To update, run: \\x1b[0m\\x1b[32;49mpython -m pip install --upgrade pip\\x1b[0m']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q transformers datasets matplotlib\n",
    "!!pip install -q accelerate torchinfo huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected operating system as Ubuntu/focal.\n",
      "Checking for curl...\n",
      "Detected curl...\n",
      "Checking for gpg...\n",
      "Detected gpg...\n",
      "Detected apt version as 2.0.9\n",
      "Running apt-get update... done.\n",
      "Installing apt-transport-https... done.\n",
      "Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n",
      "Importing packagecloud gpg key... Packagecloud gpg key imported to /etc/apt/keyrings/github_git-lfs-archive-keyring.gpg\n",
      "done.\n",
      "Running apt-get update... done.\n",
      "\n",
      "The repository is setup! You can now install packages.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  git-lfs\n",
      "0 upgraded, 1 newly installed, 0 to remove and 30 not upgraded.\n",
      "Need to get 7419 kB of archives.\n",
      "After this operation, 16.0 MB of additional disk space will be used.\n",
      "Get:1 https://packagecloud.io/github/git-lfs/ubuntu focal/main amd64 git-lfs amd64 3.3.0 [7419 kB]\n",
      "Fetched 7419 kB in 1s (5795 kB/s)\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package git-lfs.\n",
      "(Reading database ... 21090 files and directories currently installed.)\n",
      "Preparing to unpack .../git-lfs_3.3.0_amd64.deb ...\n",
      "Unpacking git-lfs (3.3.0) ...\n",
      "Setting up git-lfs (3.3.0) ...\n",
      "Git LFS initialized.\n"
     ]
    }
   ],
   "source": [
    "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\n",
    "!apt-get install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561e9b257a5f457ea3c63e9cb5ac2597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Qpd_5bdc6sxf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import T5ForConditionalGeneration, T5Config, AdamW\n",
    "from tqdm.auto import tqdm\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "J_tfT6Ll6wKh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_id = '1e1Tz4VycXhimx3ZyrxgL72VBaC0JP6By'\n",
    "destination = 'human_proteins.tsv'\n",
    "hf_name = \"t5-small\"\n",
    "max_length = 512\n",
    "tokenizer_folder = \"PROTNAME_tok\"\n",
    "save_folder = \"PROTNAME\"\n",
    "vocab_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1Mkm87uO7quF",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed73c75bbea4434910ad200a461a0a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "saved all the data to human_proteins.tsv. total size : 33.218 MB\n"
     ]
    }
   ],
   "source": [
    "file_id = '1e1Tz4VycXhimx3ZyrxgL72VBaC0JP6By'\n",
    "destination = 'human_proteins.tsv'\n",
    "\n",
    "def format_size(value):\n",
    "  if value >= 1024**3:\n",
    "    return f\"{round(value / 1024**3 , 3)} GB\"\n",
    "  elif value >= 1024**2:\n",
    "    return f\"{round(value / 1024**2 , 3)} MB\"\n",
    "  elif value >= 1024:\n",
    "    return f\"{round(value / 1024 , 3)} KB\"\n",
    "  return f\"{value} B\"\n",
    "\n",
    "# Code taken from https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "    params = { 'id' : id, 'confirm' : 1 }\n",
    "    response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "    \n",
    "    pb = tqdm(response.iter_content(CHUNK_SIZE))\n",
    "    b_total = 0\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for i,chunk in enumerate(pb):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "                b_total += len(chunk)\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                  pb.set_description(f\"written : {format_size(b_total)}\")\n",
    "                i += 1\n",
    "    print(\"\\n\")\n",
    "    print(f\"saved all the data to {destination}. total size : {format_size(os.stat(destination).st_size)}\")\n",
    "\n",
    "\n",
    "download_file_from_google_drive(file_id, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19560206c35e446995e987f9fe6c090b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "saved all the data to all_proteins.tsv. total size : 294.963 MB\n"
     ]
    }
   ],
   "source": [
    "download_file_from_google_drive(\"1FLrC9kK5-R_NwjmX_WTqT8YqchzS9zIN\", \"all_proteins.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "21QymT2_8C48",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>protein_name</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M R W Q E M G Y I F Y P R K L R</td>\n",
       "      <td>Mitochondrial-derived peptide MOTS-c</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M P G W F K K A W Y G L A S L L S F S S F I L ...</td>\n",
       "      <td>Clarin-2</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M K R R Q K R K H L E N E E S Q E T A E K G G ...</td>\n",
       "      <td>Protein FAM170A</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M D D A D P E E R N Y D N M L K M L S D L N K ...</td>\n",
       "      <td>Synaptonemal complex central element protein 3</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M A F S D L T S R T V H L Y D N W I K D A D P ...</td>\n",
       "      <td>Elongation of very long chain fatty acids prot...</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89896</th>\n",
       "      <td>M E P V D P R L E P W K H P G S Q P K T P C T ...</td>\n",
       "      <td>Protein Tat</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89897</th>\n",
       "      <td>M G G K W S K R S A P G W N A V R E R M R R T ...</td>\n",
       "      <td>Protein Nef</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89898</th>\n",
       "      <td>M L L L G A L L L L L A L P S Y G Q D T M Q G ...</td>\n",
       "      <td>Adiponectin</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89899</th>\n",
       "      <td>M G Q F I S F M Q E I P I F L Q E A L N I A L ...</td>\n",
       "      <td>Pre-glycoprotein polyprotein GP complex</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89900</th>\n",
       "      <td>M V R E D G R N F N E E R K I K I T K N I N I ...</td>\n",
       "      <td>Multifunctional fusion protein [Includes: dITP...</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89901 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sequence   \n",
       "0                        M R W Q E M G Y I F Y P R K L R  \\\n",
       "1      M P G W F K K A W Y G L A S L L S F S S F I L ...   \n",
       "2      M K R R Q K R K H L E N E E S Q E T A E K G G ...   \n",
       "3      M D D A D P E E R N Y D N M L K M L S D L N K ...   \n",
       "4      M A F S D L T S R T V H L Y D N W I K D A D P ...   \n",
       "...                                                  ...   \n",
       "89896  M E P V D P R L E P W K H P G S Q P K T P C T ...   \n",
       "89897  M G G K W S K R S A P G W N A V R E R M R R T ...   \n",
       "89898  M L L L G A L L L L L A L P S Y G Q D T M Q G ...   \n",
       "89899  M G Q F I S F M Q E I P I F L Q E A L N I A L ...   \n",
       "89900  M V R E D G R N F N E E R K I K I T K N I N I ...   \n",
       "\n",
       "                                            protein_name  length  \n",
       "0                  Mitochondrial-derived peptide MOTS-c       16  \n",
       "1                                               Clarin-2     232  \n",
       "2                                       Protein FAM170A      330  \n",
       "3        Synaptonemal complex central element protein 3       88  \n",
       "4      Elongation of very long chain fatty acids prot...     281  \n",
       "...                                                  ...     ...  \n",
       "89896                                       Protein Tat      101  \n",
       "89897                                       Protein Nef      206  \n",
       "89898                                        Adiponectin     239  \n",
       "89899           Pre-glycoprotein polyprotein GP complex      483  \n",
       "89900  Multifunctional fusion protein [Includes: dITP...     434  \n",
       "\n",
       "[89901 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"human_proteins.tsv\", sep=\"\\t\")\n",
    "dataframe = dataframe[dataframe[\"sequence\"].str.len() <= 510]\n",
    "dataframe = pd.read_csv(\"human_proteins.tsv\", sep=\"\\t\")\n",
    "dataframe = dataframe[dataframe[\"sequence\"].str.len() <= 510]\n",
    "dataframe[\"protein_name\"] = [v.split(\"(\")[0] for v in dataframe[\"protein_name\"]]\n",
    "dataframe[\"sequence\"] = [\" \".join(v) for v in dataframe[\"sequence\"]]\n",
    "\n",
    "with open(\"Sequences.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(dataframe[\"sequence\"].values))\n",
    "    \n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sequence</th>\n",
       "      <th>protein_name</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MRWQEMGYIFYPRKLR</td>\n",
       "      <td>Mitochondrial-derived peptide MOTS-c</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MPGWFKKAWYGLASLLSFSSFILIIVALVVPHWLSGKILCQTGVDL...</td>\n",
       "      <td>Clarin-2</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>MKRRQKRKHLENEESQETAEKGGGMSKSQEDALQPGSTRVAKGWSQ...</td>\n",
       "      <td>Protein FAM170A</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MDDADPEERNYDNMLKMLSDLNKDLEKLLEEMEKISVQATWMAYDM...</td>\n",
       "      <td>Synaptonemal complex central element protein 3</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MAFSDLTSRTVHLYDNWIKDADPRVEDWLLMSSPLPQTILLGFYVY...</td>\n",
       "      <td>Elongation of very long chain fatty acids prot...</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619007</th>\n",
       "      <td>529106</td>\n",
       "      <td>MNSNAPAAVIVLAAGAGTRMKSKLPKVLHEIGGRSLLMHAITAARG...</td>\n",
       "      <td>Bifunctional protein GlmU [Includes: UDP-N-ace...</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619008</th>\n",
       "      <td>529107</td>\n",
       "      <td>MSATGSDPSRRPVDLPDLSREAVPGEKVALAPGQLQLRPTRRGKAP...</td>\n",
       "      <td>Probable dual-specificity RNA methyltransferas...</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619009</th>\n",
       "      <td>529108</td>\n",
       "      <td>MVLASHNAKKLRELQRILAPAVPGLEAEQIVSAAGLGLPDVVEDAV...</td>\n",
       "      <td>dITP/XTP pyrophosphatase</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619010</th>\n",
       "      <td>529109</td>\n",
       "      <td>MLPVLTADALRTAEQAHWDEHPGDDLMGRAAAEVARHATEMLGDGP...</td>\n",
       "      <td>ADP-dependent</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619011</th>\n",
       "      <td>529110</td>\n",
       "      <td>MTAARALAGARVIVGVGGGIAAYKAAHVVRGLVASGAEVRVIPTAS...</td>\n",
       "      <td>Coenzyme A biosynthesis bifunctional protein C...</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619012 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                           sequence   \n",
       "0                0                                   MRWQEMGYIFYPRKLR  \\\n",
       "1                1  MPGWFKKAWYGLASLLSFSSFILIIVALVVPHWLSGKILCQTGVDL...   \n",
       "2                2  MKRRQKRKHLENEESQETAEKGGGMSKSQEDALQPGSTRVAKGWSQ...   \n",
       "3                3  MDDADPEERNYDNMLKMLSDLNKDLEKLLEEMEKISVQATWMAYDM...   \n",
       "4                4  MAFSDLTSRTVHLYDNWIKDADPRVEDWLLMSSPLPQTILLGFYVY...   \n",
       "...            ...                                                ...   \n",
       "619007      529106  MNSNAPAAVIVLAAGAGTRMKSKLPKVLHEIGGRSLLMHAITAARG...   \n",
       "619008      529107  MSATGSDPSRRPVDLPDLSREAVPGEKVALAPGQLQLRPTRRGKAP...   \n",
       "619009      529108  MVLASHNAKKLRELQRILAPAVPGLEAEQIVSAAGLGLPDVVEDAV...   \n",
       "619010      529109  MLPVLTADALRTAEQAHWDEHPGDDLMGRAAAEVARHATEMLGDGP...   \n",
       "619011      529110  MTAARALAGARVIVGVGGGIAAYKAAHVVRGLVASGAEVRVIPTAS...   \n",
       "\n",
       "                                             protein_name  length  \n",
       "0                   Mitochondrial-derived peptide MOTS-c       16  \n",
       "1                                                Clarin-2     232  \n",
       "2                                        Protein FAM170A      330  \n",
       "3         Synaptonemal complex central element protein 3       88  \n",
       "4       Elongation of very long chain fatty acids prot...     281  \n",
       "...                                                   ...     ...  \n",
       "619007  Bifunctional protein GlmU [Includes: UDP-N-ace...     492  \n",
       "619008  Probable dual-specificity RNA methyltransferas...     428  \n",
       "619009                          dITP/XTP pyrophosphatase      203  \n",
       "619010                                     ADP-dependent      492  \n",
       "619011  Coenzyme A biosynthesis bifunctional protein C...     425  \n",
       "\n",
       "[619012 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe2 = pd.read_csv(\"all_proteins.tsv\", sep=\"\\t\")\n",
    "dataframe2 = dataframe2[dataframe2[\"sequence\"].str.len() <= 510]\n",
    "dataframe2 = dataframe2[dataframe2[\"sequence\"].str.len() <= 510]\n",
    "dataframe2[\"protein_name\"] = [v.split(\"(\")[0] for v in dataframe2[\"protein_name\"]]\n",
    "\n",
    "with open(\"names.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([v.split(\"(\")[0].strip() for v in dataframe2[\"protein_name\"].values]))  \n",
    "\n",
    "dataframe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923a86b608ff4b80aca531dbb66e702a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/186 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcb88d6658948b8ae34dfac4887b73f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.51M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc58069d6684740854a0115c981e6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/3.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mlewand/PROT5-small\", max_length=512,\n",
    "                                                   padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 118, 89, 204, 116, 100, 118, 92, 131, 110, 115, 131, 88, 89, 104, 85, 89, 2] <s> M R W Q E M G Y I F Y P R K L R</s>\n",
      "[1, 249, 9701, 12, 25, 2] <s> Protein FAM170A</s>\n"
     ]
    }
   ],
   "source": [
    "ids = tokenizer.encode(\"M R W Q E M G Y I F Y P R K L R\")\n",
    "print(ids, tokenizer.decode(ids))\n",
    "ids = tokenizer.encode(\"Protein FAM170A\")\n",
    "print(ids, tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 249, 9701, 12, 25, 2]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919a5427c809467d9a300694859016e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89901 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053a4083a4f8401e8a91bd0a5a9791a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89901 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b596724df7214a3ab508d478079f2cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_tokenized_X = []\n",
    "_tokenized_Y = []\n",
    "\n",
    "tokenized_X = []\n",
    "tokenized_Y = []\n",
    "sizes_X = []\n",
    "sizes_Y = []\n",
    "\n",
    "max_length_inp = 512\n",
    "max_length_out = 64\n",
    "\n",
    "for x in tqdm(dataframe[\"sequence\"]):\n",
    "    input_tokens = tokenizer.encode(x)\n",
    "    tokenized_X.append(input_tokens)\n",
    "    sizes_X.append(len(input_tokens))\n",
    "\n",
    "for y in tqdm(dataframe[\"protein_name\"]):\n",
    "    out_tokens = tokenizer.encode(y)\n",
    "    tokenized_Y.append(out_tokens)\n",
    "    sizes_Y.append(len(out_tokens))\n",
    "    \n",
    "for x,y in tqdm(zip(_tokenized_X, _tokenized_Y)):\n",
    "   if len(x) <= max_length_inp and len(y) <= max_length_out:\n",
    "    tokenized_X.append(x)\n",
    "    tokenized_Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sizes ;  X : 80910, Y : 80910\n",
      "val sizes ;  X : 8991, Y : 8991\n"
     ]
    }
   ],
   "source": [
    "train_val_split = 0.9\n",
    "l = len(tokenized_X)\n",
    "split_idx = int(train_val_split * l)\n",
    "\n",
    "idxes = np.arange(l)\n",
    "r = np.random.permutation(idxes)\n",
    "\n",
    "train_idxs = r[:split_idx]\n",
    "val_idxs = r[split_idx:]\n",
    "\n",
    "train_X, train_Y = [], []\n",
    "val_X, val_Y = [], []\n",
    "\n",
    "\n",
    "for idx in train_idxs:\n",
    "    train_X.append(tokenized_X[idx])\n",
    "    train_Y.append(tokenized_Y[idx])\n",
    "    \n",
    "for idx in val_idxs:\n",
    "    val_X.append(tokenized_X[idx])\n",
    "    val_Y.append(tokenized_Y[idx])   \n",
    "    \n",
    "print(f\"train sizes ;  X : {len(train_X)}, Y : {len(train_Y)}\")\n",
    "print(f\"val sizes ;  X : {len(val_X)}, Y : {len(val_Y)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NHWqg-w4nOtm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomAADataset(Dataset):\n",
    "  def __init__(self, X, Y, max_length=512, max_length2=32):\n",
    "    self.max_length = max_length\n",
    "    self.max_length2 = max_length2 \n",
    "    self.X = X\n",
    "    self.Y = Y\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    input_tokens = self.X[idx]\n",
    "    output_tokens = self.Y[idx]\n",
    "\n",
    "    # Pad input and output tokens\n",
    "    input_tokens = input_tokens + [0] * (self.max_length - len(input_tokens))\n",
    "\n",
    "    output_tokens = output_tokens + [0] * (self.max_length2 - len(output_tokens))\n",
    "\n",
    "    return {\"input_ids\": torch.tensor(input_tokens, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(output_tokens, dtype=torch.long),\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0BpdFHmUtpda",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "from datasets import Dataset as Dataset_hf\n",
    "\n",
    "dataset = Dataset_hf.from_dict({\"source\": dataframe[\"sequence\"].values, \"target\": dataframe[\"protein_name\"].values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "kQv4-09StvBR",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  1, 118,  99,  99,  90,  92,  87, 108, 100, 110,  92, 104,  85, 115,\n",
       "         101,  92,  92,  85, 108, 204,  90, 109, 109, 116, 100, 109,  85,  89,\n",
       "          90, 131, 115,  90, 116, 131,  92, 100, 101, 101, 108, 111, 101, 110,\n",
       "         118, 104, 108, 104, 109, 109,  99, 116,  90,  89,  92, 115,  92, 115,\n",
       "         101, 104, 115, 104, 108,  88,  99, 111, 101,  92, 109, 101,  85,  87,\n",
       "          90,  89,  88, 129, 109,  85, 108,  92,  89,  99, 110, 108,  88, 104,\n",
       "          88, 111, 109,  88,  89,  92, 118, 116,  88, 100,  89, 109,  89,  88,\n",
       "         104, 100,  92, 204, 116, 104,  92,  88,  89,  90, 108,  99,  90, 104,\n",
       "          90,  99, 104, 110, 115, 101,  92,  92, 110,  88, 129,  99, 111,  92,\n",
       "         100, 109, 100,  85,  89, 100, 131, 115, 104, 104, 115,  92, 101, 101,\n",
       "         109, 100, 101, 101, 118, 110, 131, 108,  87, 100, 104, 116,  89,  88,\n",
       "          89,  92, 115,  92, 115, 110, 109, 115, 100, 108, 100, 116,  90, 101,\n",
       "         108, 116,  87, 101,  99, 118, 129, 115, 129, 108, 110, 118,  92, 104,\n",
       "         104, 101, 100, 101, 104,  89,  87, 100,  88,  89, 108,  90, 104,  90,\n",
       "         116,  87,  88,  92, 116,  88,  92,  87,  90, 116, 204,  92,  90,  89,\n",
       "         101, 101,  88,  99,  87,  87,  99,  92, 204,  87,  92, 116,  88,  88,\n",
       "          88, 109, 204, 116, 116,  92, 131,  92,  88, 116,  92, 118, 204, 101,\n",
       "          88,  87,  92, 116,  87, 110,  92,  92, 131,  92,  88,  88,  88,  87,\n",
       "          92,  89,  92,  87,  88,  88,  88,  88,  88,  88, 115, 109,  90, 131,\n",
       "         110, 101,  90, 109,  88,  88,  92,  92, 115,  88,  88,  88, 116,  92,\n",
       "         115,  88, 116,  92, 131,  92,  87,  88,  88, 116, 115,  90, 115,  92,\n",
       "         131,  92,  88,  88,  88,  88,  88,  88, 108, 116, 115,  87,  88,  88,\n",
       "          92, 101,  88,  88,  88,  88,  87, 109,  88,  92,  87,  87,  88,  85,\n",
       "          87, 115,  88,  88,  88,  88,  90, 116,  87,  87,  88, 108, 118,  90,\n",
       "         104,  88,  88, 109,  87, 116,  88, 108, 115,  88, 131,  92, 116, 131,\n",
       "          87,  92, 131,  92, 116, 108,  85,  90,  92, 115,  92, 116,  92, 115,\n",
       "          90, 108,  88,  90, 116, 116,  88,  88,  90, 131,  92,  92,  88,  90,\n",
       "         101,  88,  92,  90,  92,  92,  88,  88,  87,  92,  92,  90,  92, 115,\n",
       "          92,  89,  92, 116,  99, 129,  99, 101, 116,  92, 115, 129,  88, 131,\n",
       "          89,  89,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " 'labels': tensor([    1, 10501,   107,   406,    80,     2,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = CustomAADataset(train_X, train_Y, max_length_inp, max_length_out)\n",
    "val_dataset = CustomAADataset(val_X, val_Y, max_length_inp, max_length_out)\n",
    "\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5dbc5d48ba3430ba0753b03e4dd3122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1dae9153c74f5aac000bbd9eba37e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da6545cc62e41b0ae26429dedc0f452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=None, padding=True, max_length=512)\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "config = T5Config.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name, config=config, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dats = None\n",
    "eval_d = None\n",
    "\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"\n",
    "    Original Trainer may have a memory leak. \n",
    "    This is a workaround to avoid storing too many tensors that are not needed.\n",
    "    \"\"\"\n",
    "    global dats\n",
    "    pred_ids = torch.argmax(logits[0],dim=-1)\n",
    "    return pred_ids\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    global eval_d\n",
    "    eval_d = pred\n",
    "    labels = pred.label_ids\n",
    "    # labels = np.argmax(labels, axis=1)\n",
    "    preds = pred.predictions\n",
    "\n",
    "    tot = np.sum(labels != 0) + 1e-10\n",
    "    classified_correctly = 0\n",
    "    exact_matches = 0\n",
    "    for i in range(preds.shape[0]):\n",
    "        mask = preds[i, :] != 0\n",
    "        classified_correctly += np.sum(preds[i, mask] == labels[i, mask])\n",
    "        exact_matches += np.all(preds[i,:] == labels[i, :])\n",
    "            \n",
    "    return {\"matches\": classified_correctly / tot, \"exact_matches\" : exact_matches / preds.shape[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/PROT5-small is already a clone of https://huggingface.co/mlewand/PROT5-small-v2. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='75870' max='75870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [75870/75870 2:57:39, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Exact Matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.327100</td>\n",
       "      <td>0.254362</td>\n",
       "      <td>0.705893</td>\n",
       "      <td>0.453898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.243700</td>\n",
       "      <td>0.222853</td>\n",
       "      <td>0.737829</td>\n",
       "      <td>0.462351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.215800</td>\n",
       "      <td>0.201158</td>\n",
       "      <td>0.755404</td>\n",
       "      <td>0.478812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.199100</td>\n",
       "      <td>0.190414</td>\n",
       "      <td>0.768285</td>\n",
       "      <td>0.503392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.180720</td>\n",
       "      <td>0.777898</td>\n",
       "      <td>0.516294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.177700</td>\n",
       "      <td>0.172958</td>\n",
       "      <td>0.786376</td>\n",
       "      <td>0.535536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.170200</td>\n",
       "      <td>0.168122</td>\n",
       "      <td>0.792378</td>\n",
       "      <td>0.543099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.163700</td>\n",
       "      <td>0.164963</td>\n",
       "      <td>0.797606</td>\n",
       "      <td>0.552664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.158100</td>\n",
       "      <td>0.159285</td>\n",
       "      <td>0.801304</td>\n",
       "      <td>0.559671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.153300</td>\n",
       "      <td>0.157703</td>\n",
       "      <td>0.806996</td>\n",
       "      <td>0.568902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.154211</td>\n",
       "      <td>0.810504</td>\n",
       "      <td>0.574686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.145300</td>\n",
       "      <td>0.153186</td>\n",
       "      <td>0.812860</td>\n",
       "      <td>0.577578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>0.148574</td>\n",
       "      <td>0.816850</td>\n",
       "      <td>0.583027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>0.147302</td>\n",
       "      <td>0.819326</td>\n",
       "      <td>0.584140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.136200</td>\n",
       "      <td>0.145933</td>\n",
       "      <td>0.820633</td>\n",
       "      <td>0.586364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.133600</td>\n",
       "      <td>0.145205</td>\n",
       "      <td>0.822662</td>\n",
       "      <td>0.589701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.143769</td>\n",
       "      <td>0.824107</td>\n",
       "      <td>0.590146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>0.141203</td>\n",
       "      <td>0.826394</td>\n",
       "      <td>0.591369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.140678</td>\n",
       "      <td>0.827736</td>\n",
       "      <td>0.595262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.125600</td>\n",
       "      <td>0.139339</td>\n",
       "      <td>0.828269</td>\n",
       "      <td>0.594595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>0.138563</td>\n",
       "      <td>0.829593</td>\n",
       "      <td>0.596708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.122700</td>\n",
       "      <td>0.138220</td>\n",
       "      <td>0.830711</td>\n",
       "      <td>0.596263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.121500</td>\n",
       "      <td>0.137194</td>\n",
       "      <td>0.831106</td>\n",
       "      <td>0.597709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.120500</td>\n",
       "      <td>0.135366</td>\n",
       "      <td>0.832293</td>\n",
       "      <td>0.597931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.119700</td>\n",
       "      <td>0.134556</td>\n",
       "      <td>0.832688</td>\n",
       "      <td>0.598042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>0.141632</td>\n",
       "      <td>0.829404</td>\n",
       "      <td>0.592036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.164500</td>\n",
       "      <td>0.178037</td>\n",
       "      <td>0.818913</td>\n",
       "      <td>0.588255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.198600</td>\n",
       "      <td>0.203193</td>\n",
       "      <td>0.803660</td>\n",
       "      <td>0.577911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.254200</td>\n",
       "      <td>0.229447</td>\n",
       "      <td>0.767683</td>\n",
       "      <td>0.535091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.288900</td>\n",
       "      <td>0.243270</td>\n",
       "      <td>0.748611</td>\n",
       "      <td>0.509287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=75870, training_loss=0.1664552430413969, metrics={'train_runtime': 10659.2535, 'train_samples_per_second': 227.718, 'train_steps_per_second': 7.118, 'total_flos': 3.285151547129856e+17, 'train_loss': 0.1664552430413969, 'epoch': 30.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"PROT5-small\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=30,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    fp16=True,  # Enable mixed precision training if your GPU supports it\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=\"mlewand/PROT5-small-v2\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=None,\n",
    "    compute_metrics=compute_metrics,\n",
    "    preprocess_logits_for_metrics= preprocess_logits_for_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6623f592f0642129787066e1d631cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8991 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5377/8991\n"
     ]
    }
   ],
   "source": [
    "def decode(pred):\n",
    "    mask = pred != 0\n",
    "    return tokenizer.decode(pred[mask][1:-1])\n",
    "    \n",
    "model = model.to(\"cpu\")\n",
    "val_dl = DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "exact_match = 0\n",
    "i = 0\n",
    "\n",
    "with tqdm(val_dl) as pb:\n",
    "    for batch in val_dl:\n",
    "        ret = model(**batch)\n",
    "        pred = torch.argmax(ret.logits, axis=-1).reshape(-1)\n",
    "    \n",
    "        exact_match += torch.all(pred == batch['labels']).item()\n",
    "        i += 1\n",
    "        # print(decode(pred), decode(batch['labels']))\n",
    "        pb.update(1)\n",
    "        pb.set_description(f\"{exact_match}/{i} ; Acc : {round( 100. * exact_match / i , 2)}\")\n",
    "\n",
    "print(f\"{exact_match}/{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mlewand/PROT5-small-v2/commit/b9b96bdfe83002baad22a882a4519aad615e70a4', commit_message='Upload tokenizer', commit_description='', oid='b9b96bdfe83002baad22a882a4519aad615e70a4', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\"mlewand/PROT5-small-v2\")\n",
    "#model.push_to_hub(\"mlewand/PROT5-small-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0de8bb85911b427d8294a81d94939ce4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cd698668f6984461956d307c4cbce5cc",
       "IPY_MODEL_99170237c3444b13a432b8c374fc1473",
       "IPY_MODEL_43cf4edef7a043928b9508bde88b9374"
      ],
      "layout": "IPY_MODEL_443cfdca91394190a0c800b1e1e654eb"
     }
    },
    "2106053b50d844a5a4b0b466a5614841": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fe2f7b256874bf384386a4fa5123ea3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d217e7538a049be9fb50bacf859e9ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43cf4edef7a043928b9508bde88b9374": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d217e7538a049be9fb50bacf859e9ac",
      "placeholder": "​",
      "style": "IPY_MODEL_2fe2f7b256874bf384386a4fa5123ea3",
      "value": " 0/198 [00:00&lt;?, ?it/s]"
     }
    },
    "443cfdca91394190a0c800b1e1e654eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71b09a2f29c44961b792ddf69ea8f150": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "971715e9020f4f68ab3a4f024c7e85bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "99170237c3444b13a432b8c374fc1473": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2106053b50d844a5a4b0b466a5614841",
      "max": 198,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_971715e9020f4f68ab3a4f024c7e85bb",
      "value": 0
     }
    },
    "99599d201e274dacb4d8c0dc8ffb80b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd698668f6984461956d307c4cbce5cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71b09a2f29c44961b792ddf69ea8f150",
      "placeholder": "​",
      "style": "IPY_MODEL_99599d201e274dacb4d8c0dc8ffb80b9",
      "value": "  0%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
