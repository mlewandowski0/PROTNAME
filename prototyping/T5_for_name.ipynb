{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KMTa-R8A6jiI",
    "outputId": "268501f2-cc48-4b81-d027-87d5ae402d45",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"\\x1b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\\x1b[0m\\x1b[33m\",\n",
       " '\\x1b[0m',\n",
       " '\\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m A new release of pip is available: \\x1b[0m\\x1b[31;49m23.0.1\\x1b[0m\\x1b[39;49m -> \\x1b[0m\\x1b[32;49m23.1.1\\x1b[0m',\n",
       " '\\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m To update, run: \\x1b[0m\\x1b[32;49mpython -m pip install --upgrade pip\\x1b[0m']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q transformers datasets matplotlib\n",
    "!!pip install -q accelerate torchinfo huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected operating system as Ubuntu/focal.\n",
      "Checking for curl...\n",
      "Detected curl...\n",
      "Checking for gpg...\n",
      "Detected gpg...\n",
      "Detected apt version as 2.0.9\n",
      "Running apt-get update... done.\n",
      "Installing apt-transport-https... done.\n",
      "Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n",
      "Importing packagecloud gpg key... Packagecloud gpg key imported to /etc/apt/keyrings/github_git-lfs-archive-keyring.gpg\n",
      "done.\n",
      "Running apt-get update... done.\n",
      "\n",
      "The repository is setup! You can now install packages.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "git-lfs is already the newest version (3.3.0).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 26 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | bash\n",
    "!apt-get install git-lfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414f0a91a11f490bbbd87064393c2b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Qpd_5bdc6sxf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import tqdm\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import T5ForConditionalGeneration, T5Config, AdamW\n",
    "from tqdm.auto import tqdm\n",
    "from accelerate import Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "J_tfT6Ll6wKh",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_id = '1yXvDTRRxjCLyAf4icU1sEMKF0NpssCnC'\n",
    "destination = 'human_proteins.tsv'\n",
    "hf_name = \"t5-small\"\n",
    "max_length = 512\n",
    "tokenizer_folder = \"PROTNAME_tok\"\n",
    "save_folder = \"PROTNAME\"\n",
    "vocab_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1Mkm87uO7quF",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21c237af77e941f69e2f5ae57302a465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "saved all the data to human_proteins.tsv. total size : 12.9 MB\n"
     ]
    }
   ],
   "source": [
    "file_id = '1yXvDTRRxjCLyAf4icU1sEMKF0NpssCnC'\n",
    "destination = 'human_proteins.tsv'\n",
    "\n",
    "def format_size(value):\n",
    "  if value >= 1024**3:\n",
    "    return f\"{round(value / 1024**3 , 3)} GB\"\n",
    "  elif value >= 1024**2:\n",
    "    return f\"{round(value / 1024**2 , 3)} MB\"\n",
    "  elif value >= 1024:\n",
    "    return f\"{round(value / 1024 , 3)} KB\"\n",
    "  return f\"{value} B\"\n",
    "\n",
    "# Code taken from https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "    params = { 'id' : id, 'confirm' : 1 }\n",
    "    response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "    \n",
    "    pb = tqdm(response.iter_content(CHUNK_SIZE))\n",
    "    b_total = 0\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for i,chunk in enumerate(pb):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)\n",
    "                b_total += len(chunk)\n",
    "\n",
    "                if i % 1000 == 0:\n",
    "                  pb.set_description(f\"written : {format_size(b_total)}\")\n",
    "                i += 1\n",
    "    print(\"\\n\")\n",
    "    print(f\"saved all the data to {destination}. total size : {format_size(os.stat(destination).st_size)}\")\n",
    "\n",
    "\n",
    "download_file_from_google_drive(file_id, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "21QymT2_8C48",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"human_proteins.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ibHSmvdTcIra",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe = dataframe[dataframe[\"Sequence\"].str.len() <= 510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe[\"Protein Name\"] = [v.split(\"(\")[0] for v in dataframe[\"Protein Name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Protein Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MRWQEMGYIFYPRKLR</td>\n",
       "      <td>Mitochondrial-derived peptide MOTS-c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MPGWFKKAWYGLASLLSFSSFILIIVALVVPHWLSGKILCQTGVDL...</td>\n",
       "      <td>Clarin-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MKRRQKRKHLENEESQETAEKGGGMSKSQEDALQPGSTRVAKGWSQ...</td>\n",
       "      <td>Protein FAM170A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MDDADPEERNYDNMLKMLSDLNKDLEKLLEEMEKISVQATWMAYDM...</td>\n",
       "      <td>Synaptonemal complex central element protein 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MAFSDLTSRTVHLYDNWIKDADPRVEDWLLMSSPLPQTILLGFYVY...</td>\n",
       "      <td>Elongation of very long chain fatty acids prot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20417</th>\n",
       "      <td>MPLASPIQHHEVTRGVAPSMALRDGVCRIPLSAEFTAQCTDSQAPQ...</td>\n",
       "      <td>Putative uncharacterized protein PRO3102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20418</th>\n",
       "      <td>MVRPHLLKKKILGRVWWLMPVVLALWEAEVGGSLEVRSLRPAWPTW</td>\n",
       "      <td>Putative uncharacterized protein PRO2829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20419</th>\n",
       "      <td>MAETYRRSRQHEQLPGQRHMDLLTGYSKLIQSRLKLLLHLGSQPPV...</td>\n",
       "      <td>Putative uncharacterized protein DKFZp434L187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20420</th>\n",
       "      <td>MAHHSLNTFYIWHNNVLHTHLVFFLPHLLNQPFSRGSFLIWLLLCW...</td>\n",
       "      <td>Putative uncharacterized protein encoded by LI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20421</th>\n",
       "      <td>MGRKEHESPSQPHMCGWEDSQKPSVPSHGPKTPSCKGVKAPHSSRP...</td>\n",
       "      <td>Putative uncharacterized protein GUCA1ANB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12617 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sequence   \n",
       "0                                       MRWQEMGYIFYPRKLR  \\\n",
       "4      MPGWFKKAWYGLASLLSFSSFILIIVALVVPHWLSGKILCQTGVDL...   \n",
       "6      MKRRQKRKHLENEESQETAEKGGGMSKSQEDALQPGSTRVAKGWSQ...   \n",
       "7      MDDADPEERNYDNMLKMLSDLNKDLEKLLEEMEKISVQATWMAYDM...   \n",
       "8      MAFSDLTSRTVHLYDNWIKDADPRVEDWLLMSSPLPQTILLGFYVY...   \n",
       "...                                                  ...   \n",
       "20417  MPLASPIQHHEVTRGVAPSMALRDGVCRIPLSAEFTAQCTDSQAPQ...   \n",
       "20418     MVRPHLLKKKILGRVWWLMPVVLALWEAEVGGSLEVRSLRPAWPTW   \n",
       "20419  MAETYRRSRQHEQLPGQRHMDLLTGYSKLIQSRLKLLLHLGSQPPV...   \n",
       "20420  MAHHSLNTFYIWHNNVLHTHLVFFLPHLLNQPFSRGSFLIWLLLCW...   \n",
       "20421  MGRKEHESPSQPHMCGWEDSQKPSVPSHGPKTPSCKGVKAPHSSRP...   \n",
       "\n",
       "                                            Protein Name  \n",
       "0                  Mitochondrial-derived peptide MOTS-c   \n",
       "4                                               Clarin-2  \n",
       "6                                       Protein FAM170A   \n",
       "7        Synaptonemal complex central element protein 3   \n",
       "8      Elongation of very long chain fatty acids prot...  \n",
       "...                                                  ...  \n",
       "20417           Putative uncharacterized protein PRO3102  \n",
       "20418           Putative uncharacterized protein PRO2829  \n",
       "20419      Putative uncharacterized protein DKFZp434L187  \n",
       "20420  Putative uncharacterized protein encoded by LI...  \n",
       "20421         Putative uncharacterized protein GUCA1ANB   \n",
       "\n",
       "[12617 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jNw9bimPQ2KC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"Sequences.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(dataframe[\"Sequence\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xfulKvgLcDib",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"names.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join([v.split(\"(\")[0].strip() for v in dataframe[\"Protein Name\"].values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ARc_I92dYj-x",
    "outputId": "e46b7e68-975a-4b05-f409-f5b124f16fd3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['input_tokenizer_aminoacids/vocab.json',\n",
       " 'input_tokenizer_aminoacids/merges.txt']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "# Train the input tokenizer \n",
    "input_tokenizer = ByteLevelBPETokenizer()\n",
    "input_tokenizer.train(files=[\"Sequences.txt\"], vocab_size=261, \n",
    "                      special_tokens=[\"<pad>\", \"<s>\", \"</s>\",\"<unk>\"])\n",
    "\n",
    "input_tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", input_tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", input_tokenizer.token_to_id(\"<s>\")),\n",
    ")\n",
    "\n",
    "# save the input tokenizer \n",
    "os.makedirs(\"input_tokenizer_aminoacids\", exist_ok=True)\n",
    "input_tokenizer.save_model(\"input_tokenizer_aminoacids\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ljAnfvj5Ng4",
    "outputId": "c69c97d2-ca85-42fd-c3ca-c07b8635b9ef",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_tokenizer.encode(\"MRWQEMGYIFYPRKLR\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JKiAXJLnZHIR",
    "outputId": "40970de2-aecb-4c24-ae38-0e2570be973e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['output_tokenizer_names/vocab.json', 'output_tokenizer_names/merges.txt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the output tokenizer \n",
    "from tokenizers import SentencePieceBPETokenizer\n",
    "\n",
    "output_tokenizer = SentencePieceBPETokenizer()\n",
    "output_tokenizer.train(files=[\"names.txt\"], vocab_size=32000,min_frequency=2, special_tokens=[\"<pad>\",\"<s>\",\"</s>\",\"<unk>\"])\n",
    "\n",
    "# save the input tokenizer \n",
    "os.makedirs(\"output_tokenizer_names\", exist_ok=True)\n",
    "input_tokenizer.save_model(\"output_tokenizer_names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tcfQUAHpdaUB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "e = output_tokenizer.encode(\"Protein FAM170A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁Protein', '▁FAM17', '0', 'A']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3fd695ac3ae4b3c8acff71dad26ad47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12617 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1e54f1654945f59802c6a33ae1ff27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12617 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07015666ad6546c797c19968e64e724d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_tokenized_X = []\n",
    "_tokenized_Y = []\n",
    "\n",
    "tokenized_X = []\n",
    "tokenized_Y = []\n",
    "sizes_X = []\n",
    "sizes_Y = []\n",
    "\n",
    "max_length_inp = 512\n",
    "max_length_out = 32 \n",
    "\n",
    "input_tok = PreTrainedTokenizerFast(tokenizer_object=input_tokenizer,\n",
    "                                                   max_length=512,\n",
    "                                                   padding=True)\n",
    "\n",
    "output_tok = PreTrainedTokenizerFast(tokenizer_object=output_tokenizer,\n",
    "                                                   max_length=32,\n",
    "                                                   padding=True)\n",
    "\n",
    "for x in tqdm(dataframe[\"Sequence\"]):\n",
    "    input_tokens = input_tok.encode(x)\n",
    "    tokenized_X.append(input_tokens)\n",
    "    sizes_X.append(len(input_tokens))\n",
    "\n",
    "for y in tqdm(dataframe[\"Protein Name\"]):\n",
    "    out_tokens = output_tok.encode(y)\n",
    "    tokenized_Y.append(out_tokens)\n",
    "    sizes_Y.append(len(out_tokens))\n",
    "    \n",
    "for x,y in tqdm(zip(_tokenized_X, _tokenized_Y)):\n",
    "   if len(x) <= max_length_inp and len(y) <= max_length_out:\n",
    "    tokenized_X.append(x)\n",
    "    tokenized_Y.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "NHWqg-w4nOtm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomAADataset(Dataset):\n",
    "  def __init__(self, max_length=512, max_length2=32):\n",
    "    self.max_length = max_length\n",
    "    self.max_length2 = max_length2 \n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(tokenized_X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    input_tokens = tokenized_X[idx]\n",
    "    output_tokens = tokenized_Y[idx]\n",
    "\n",
    "    # Pad input and output tokens\n",
    "    input_tokens = input_tokens + [input_tokenizer.token_to_id(\"<pad>\")] * (self.max_length - len(input_tokens))\n",
    "\n",
    "    output_tokens = output_tokens + [output_tokenizer.token_to_id(\"<pad>\")] * (self.max_length2 - len(output_tokens))\n",
    "\n",
    "    return {\"input_ids\": torch.tensor(input_tokens, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(output_tokens, dtype=torch.long),\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0BpdFHmUtpda",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "from datasets import Dataset as Dataset_hf\n",
    "\n",
    "dataset = Dataset_hf.from_dict({\"source\": dataframe[\"Sequence\"].values, \"target\": dataframe[\"Protein Name\"].values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "kQv4-09StvBR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create dataset instances\n",
    "train_dataset = CustomAADataset(max_length_inp, max_length_out)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config\n",
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=None, padding=True, max_length=512)\n",
    "\n",
    "# Load T5 model\n",
    "config = T5Config.from_pretrained(\"mlewand/PROT5-small\")\n",
    "model = T5ForConditionalGeneration(config)\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/PROT5-small is already a clone of https://huggingface.co/mlewand/PROT5-small. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7890' max='7890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7890/7890 18:26, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.331400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.346700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.347200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.329600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.336500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.336300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.329100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.322900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.329300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.319700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.314600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.317100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.310700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.307100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.308900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.306500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.299300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.299400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>0.301500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.288400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>0.293800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.296800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>0.286500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.290400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6250</td>\n",
       "      <td>0.284500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.279700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6750</td>\n",
       "      <td>0.284100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.279000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7250</td>\n",
       "      <td>0.277800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.277500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7750</td>\n",
       "      <td>0.276400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7890, training_loss=0.306198959930768, metrics={'train_runtime': 1106.3744, 'train_samples_per_second': 114.039, 'train_steps_per_second': 7.131, 'total_flos': 1.707607509172224e+16, 'train_loss': 0.306198959930768, 'epoch': 10.0})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"PROT5-small\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=10,\n",
    "    logging_steps = 250,\n",
    "    fp16=True,  # Enable mixed precision training if your GPU supports it\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=\"mlewand/PROT5-small\"\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=None,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "input_ids = batch[\"input_ids\"].to(\"cuda\")\n",
    "labels = batch[\"labels\"].to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = model(input_ids=input_ids, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = torch.argmax(outputs.logits, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta-1,4-galactosyltransferase 5  Protein 5 \n",
      "Gamma-aminobutyric acid receptor subunit gamma-1  Gamma-aminobutyric acid receptor subunit rho \n",
      "General transcription factor IIE subunit 1  Keratin, transcription factor IIH subunit 1 \n",
      "Dehydrogenase/reductase SDR family member 7  Pregnancy-specific SDR family member 7 \n",
      "WAP four-disulfide core domain protein 13 Putative four-disulfide core domain protein 3\n",
      "Tripartite motif-containing protein 73  E3 motif-containing protein 74 \n",
      "Sex comb on midleg-like protein 4 Zinc comb on midleg-like protein 4\n",
      "Neuromedin-B [Cleaved into: Neuromedin-B-32; Neuromedin-B] Putative [Cleaved into: Neuromedin-B-32; Neuromedin-B]\n",
      "Sperm protein associated with the nucleus on the X chromosome N5  Endogenous protein associated with the nucleus on the X chromosome D5 \n",
      "Eukaryotic translation initiation factor 1  Histone translation initiation factor 5A \n",
      "Carcinoembryonic antigen-related cell adhesion molecule 7  Protein antigen-related cell adhesion molecule 8 \n",
      "Interferon-induced protein 44  Tubulin protein with \n",
      "Prenylated Rab acceptor protein 1  Transmembraneylated Rab acceptor protein 1 \n",
      "Peptidyl-prolyl cis-trans isomerase NIMA-interacting 1  Protein cis-trans isomerase FKBP 1 \n",
      "Immunoglobulin lambda joining 1 Immunoglobulin lambda joining 1\n",
      "Transmembrane protein 140 Transmembrane protein 21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for v in range(len(labels)):\n",
    "    y_true = labels[v][labels[v] != 0]\n",
    "    y_hat  = preds[v][preds[v] != 0]\n",
    "    print(output_tokenizer.decode(y_true.cpu().detach().numpy()), output_tokenizer.decode(y_hat.cpu().detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transmembrane protein 140'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "0de8bb85911b427d8294a81d94939ce4",
      "cd698668f6984461956d307c4cbce5cc",
      "99170237c3444b13a432b8c374fc1473",
      "43cf4edef7a043928b9508bde88b9374",
      "443cfdca91394190a0c800b1e1e654eb",
      "71b09a2f29c44961b792ddf69ea8f150",
      "99599d201e274dacb4d8c0dc8ffb80b9",
      "2106053b50d844a5a4b0b466a5614841",
      "971715e9020f4f68ab3a4f024c7e85bb",
      "3d217e7538a049be9fb50bacf859e9ac",
      "2fe2f7b256874bf384386a4fa5123ea3"
     ]
    },
    "id": "g05067UixGnb",
    "outputId": "9d323d51-89df-4aa8-c1f8-5110eb4c927c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "accelerator = Accelerator(mixed_precision=\"bf16\")\n",
    "device = accelerator.device\n",
    "\n",
    "# Load T5 model\n",
    "config = T5Config.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration(config)\n",
    "model.to(device)\n",
    "\n",
    "# Set hyperparameters\n",
    "num_epochs = 3\n",
    "learning_rate = 5e-4\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "model, optimizer, data = accelerator.prepare(model, optimizer, train_loader)\n",
    "\n",
    "log_every = 100\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    loss_total = 0\n",
    "    samples_seen_so_far = 0\n",
    "    \n",
    "    pb = tqdm(train_loader)\n",
    "    for i,batch in enumerate(pb):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        loss_total += loss.item() * input_ids.shape[0]\n",
    "        samples_seen_so_far += input_ids.shape[0]\n",
    "        \n",
    "        # backward pass\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % log_every == 0:\n",
    "            pb.set_description(f\"Loss : {round(loss_total / samples_seen_so_far, 4)}\")\n",
    "\n",
    "    print(f\"Train loss: {loss_total / samples_seen_so_far}\")\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0de8bb85911b427d8294a81d94939ce4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cd698668f6984461956d307c4cbce5cc",
       "IPY_MODEL_99170237c3444b13a432b8c374fc1473",
       "IPY_MODEL_43cf4edef7a043928b9508bde88b9374"
      ],
      "layout": "IPY_MODEL_443cfdca91394190a0c800b1e1e654eb"
     }
    },
    "2106053b50d844a5a4b0b466a5614841": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fe2f7b256874bf384386a4fa5123ea3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d217e7538a049be9fb50bacf859e9ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43cf4edef7a043928b9508bde88b9374": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d217e7538a049be9fb50bacf859e9ac",
      "placeholder": "​",
      "style": "IPY_MODEL_2fe2f7b256874bf384386a4fa5123ea3",
      "value": " 0/198 [00:00&lt;?, ?it/s]"
     }
    },
    "443cfdca91394190a0c800b1e1e654eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71b09a2f29c44961b792ddf69ea8f150": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "971715e9020f4f68ab3a4f024c7e85bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "99170237c3444b13a432b8c374fc1473": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2106053b50d844a5a4b0b466a5614841",
      "max": 198,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_971715e9020f4f68ab3a4f024c7e85bb",
      "value": 0
     }
    },
    "99599d201e274dacb4d8c0dc8ffb80b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd698668f6984461956d307c4cbce5cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71b09a2f29c44961b792ddf69ea8f150",
      "placeholder": "​",
      "style": "IPY_MODEL_99599d201e274dacb4d8c0dc8ffb80b9",
      "value": "  0%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
